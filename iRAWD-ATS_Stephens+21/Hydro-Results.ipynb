{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make all hydro plots \n",
    "Stephens+ 2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# %pylab ipympl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib as mpl\n",
    "import scipy.integrate\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "# spherical harmonics tools\n",
    "import pyshtools.expand \n",
    "import pyshtools.spectralanalysis\n",
    "\n",
    "##########################################################################\n",
    "# Loading NuGridPy and PPMPy\n",
    "# we may want to load special versions\n",
    "# pwd = os. getcwd()\n",
    "# nugridpy_git = \"9414d08\" # make pre-processing files and marker options for multiple abu_profile plot\n",
    "# nugridpy_dir = '/user/scratch14_ppmstar/fherwig/repos/NuGridPy'\n",
    "# os.chdir(nugridpy_dir)\n",
    "# git_hash = os.popen('git rev-parse --short HEAD').read().rstrip()\n",
    "# if not git_hash == nugridpy_git: \n",
    "#     print(\"WARNING: NuGridPy should be on \"+nugridpy_git+\" but is on \"+git_hash)\n",
    "# sys.path.insert(0,nugridpy_dir)  \n",
    "import nugridpy.ascii_table as table\n",
    "from nugridpy import nugridse as nuse\n",
    "import nugridpy.utils as utils\n",
    "import nugridpy.astronomy as ast\n",
    "\n",
    "\n",
    "# pyppm_git = '582dd18'\n",
    "# pyppm_dir = '/user/scratch14_ppmstar/fherwig/repos/PyPPM/'\n",
    "# os.chdir(pyppm_dir)\n",
    "# git_hash = os.popen('git rev-parse --short HEAD').read().rstrip()\n",
    "# if not git_hash == pyppm_git: \n",
    "#     print(\"WARNING: PyPPM should be on \"+pyppm_git+\" but is on \"+git_hash)\n",
    "pyppm_dir = '/user/niagara_scratch_fherwig/repos/PyPPM/'\n",
    "sys.path.insert(0,pyppm_dir)  \n",
    "from ppmpy import ppm\n",
    "# os.chdir(pwd)\n",
    "##########################################################################\n",
    "\n",
    "from astropy import constants as const\n",
    "from astropy import units as u\n",
    "\n",
    "Msun = (const.M_sun.to(u.g)).value\n",
    "Rsun = (const.R_sun.to(u.cm)).value\n",
    "\n",
    "cb = utils.linestylecb # colours\n",
    "\n",
    "# plot things\n",
    "ifig = 0\n",
    "ptrack = {}\n",
    "\n",
    "# figure sizes\n",
    "stdSize = 3.5\n",
    "stdRatio = 4./3.\n",
    "mollSize = 2.5\n",
    "mollRatio = 3.5 / 2.5\n",
    "horizSize = 3.3\n",
    "horizRatio = 6 / 3.5\n",
    "\n",
    "# turn off matplotlib messages\n",
    "logging.getLogger(\"matplotlib\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to easily compare between the two models, a master dictionary is used\n",
    "run_dependent_quantities = ['moms', 'rprof', 'dump0', 'time0', 'dumpMax', 'dumps', 'times', 'initbase', \n",
    "                            'simDump0', 'simTime0', 'simDumpMax', 'mbot', 'mtop']\n",
    "runs = ['n15', 'n16', 'n17']\n",
    "\n",
    "# to get \"run_dependent_quantities\", use a named tuple\n",
    "allruns = collections.namedtuple('allruns', run_dependent_quantities)\n",
    "\n",
    "# temporary fill values for anything past rprof\n",
    "tempfill = [40] * (len(run_dependent_quantities)-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the paper may change since the origin of this notebook, the figures and what they are conveying should not change significantly. The plots are done in sections like that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "collect all of the quantities for each named tuple and create the master dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N15\n",
    "moms_dir = '/data/ASDR/PPMstar/LowZRAWD/N15-LowZRAWD-768-10x-burn-moms/myavsbq'\n",
    "rprof_dir = '/data/ASDR/PPMstar/LowZRAWD/N15-LowZRAWD-768-10x-burn-moms/prfs/'\n",
    "\n",
    "var_list = ['xc','ux','uy','uz','|ut|','|ur|','|w|','P','rho','fv']\n",
    "n15 = allruns(ppm.MomsDataSet(moms_dir,400,2,var_list,rprofset=ppm.RprofSet(rprof_dir)),\n",
    "              ppm.RprofSet(rprof_dir),*tempfill)\n",
    "\n",
    "# N16\n",
    "moms_dir = '/data/ASDR/PPMstar/LowZRAWD/N16-LowZRAWD-1536-10x-burn-moms/myavsbq'\n",
    "rprof_dir = '/data/ASDR/PPMstar/LowZRAWD/N16-LowZRAWD-1536-10x-burn-moms/prfs/'\n",
    "\n",
    "var_list = ['xc','ux','uy','uz','|ut|','|ur|','|w|','P','rho','fv']\n",
    "n16 = allruns(ppm.MomsDataSet(moms_dir,400,2,var_list,rprofset=ppm.RprofSet(rprof_dir)),\n",
    "              ppm.RprofSet(rprof_dir),*tempfill)\n",
    "\n",
    "# N17\n",
    "moms_dir = '/data/ASDR/PPMstar/LowZRAWD/N17-LowZRAWD-1152-100x-burn-moms/myavsbq'\n",
    "rprof_dir = '/data/ASDR/PPMstar/LowZRAWD/N17-LowZRAWD-1152-100x-burn-moms/prfs/'\n",
    "\n",
    "var_list = ['xc','ux','uy','uz','|ut|','|ur|','|w|','P','rho','fv']\n",
    "n17 = allruns(ppm.MomsDataSet(moms_dir,400,2,var_list,rprofset=ppm.RprofSet(rprof_dir)),\n",
    "              ppm.RprofSet(rprof_dir),*tempfill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convenience functions used throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a mass coordinate to radius\n",
    "def m2r(masscoord, myrun, dump):\n",
    "    # stop printing, too much\n",
    "    devnull = open(os.devnull, 'w')\n",
    "    with RedirectStdStreams(stdout=devnull, stderr=devnull):\n",
    "        m = myrun.rprof.compute_m(dump)\n",
    "        r = myrun.rprof.get('R',fname=dump,resolution='l')\n",
    "    return ppm.interpolate(m,r,masscoord)\n",
    "\n",
    "def readSCFile(initbase, fileExt, dump):\n",
    "    \"\"\"\n",
    "    Read in a .shell or .central file at dump\n",
    "    Returns the data and header dictionaries\n",
    "    \"\"\"\n",
    "\n",
    "    # counters\n",
    "    headerLines = 0\n",
    "    dataLines = 0\n",
    "\n",
    "    # lists to hold results\n",
    "    data_keys =[]\n",
    "    header = {}\n",
    "\n",
    "    # open the file\n",
    "    openfile = initbase + '-{0:04d}.{1:s}'.format(dump, fileExt)\n",
    "\n",
    "    with open(openfile) as myfile:\n",
    "\n",
    "        # get all lines\n",
    "        lines = [line.rstrip() for line in myfile]\n",
    "\n",
    "        # run through the lines\n",
    "        for line in lines:\n",
    "\n",
    "            # grab the data keys\n",
    "            if line.startswith('#'):\n",
    "                data_keys.extend(line.split(' ')[1:])\n",
    "                headerLines += 1\n",
    "\n",
    "            # Grab the header data\n",
    "            elif line.find('=') != -1:\n",
    "\n",
    "                # split across = sign, remove whitespace\n",
    "                split = line.split('=')\n",
    "\n",
    "                # Now I need to know what type the header should be!\n",
    "                if split[1].strip().isdecimal():\n",
    "                    hval = int(split[1].strip())\n",
    "                elif split[1].strip().find('.') != -1:\n",
    "                    hval = float(split[1].strip())\n",
    "                else:\n",
    "                    hval = split[1].strip()\n",
    "\n",
    "                # put into dictionary\n",
    "                header[split[0].strip()] = hval\n",
    "                headerLines += 1\n",
    "\n",
    "            # we are now reading in data, this is after all header data\n",
    "            else:\n",
    "\n",
    "                # if we are at the first line, create arrays and dict\n",
    "                if dataLines == 0:\n",
    "                    data = collections.OrderedDict(zip(data_keys,\n",
    "                                    map(np.zeros, [len(lines) - headerLines] * len(data_keys))))\n",
    "\n",
    "                # split the line into its numbers\n",
    "                line = \" \".join(line.split())\n",
    "                split = line.split(' ')\n",
    "\n",
    "                for i, key in enumerate(data.keys()):\n",
    "                    data[key][dataLines] = float(split[i])\n",
    "\n",
    "                # update line number\n",
    "                dataLines += 1\n",
    "                \n",
    "    return data, header\n",
    "\n",
    "# use remove print to console at certain points then return\n",
    "class RedirectStdStreams(object):\n",
    "    def __init__(self, stdout=None, stderr=None):\n",
    "        self._stdout = stdout or sys.stdout\n",
    "        self._stderr = stderr or sys.stderr\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.old_stdout, self.old_stderr = sys.stdout, sys.stderr\n",
    "        self.old_stdout.flush(); self.old_stderr.flush()\n",
    "        sys.stdout, sys.stderr = self._stdout, self._stderr\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self._stdout.flush(); self._stderr.flush()\n",
    "        sys.stdout = self.old_stdout\n",
    "        sys.stderr = self.old_stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining radial and horizontal timescales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shellNpoints(r_onShell):\n",
    "\n",
    "    # get npoints to ensure a perfect sampling up to an lmax\n",
    "    npoints = np.zeros(len(r_onShell), dtype='int32')\n",
    "    lmax = np.zeros(len(r_onShell), dtype='int32')\n",
    "\n",
    "    for i, radius in enumerate(r_onShell):\n",
    "\n",
    "        lmax_r, N, npoints_r = hydro.moms.sphericalHarmonics_lmax(radius)\n",
    "\n",
    "        if lmax_r > my_lmax:\n",
    "            lmax[i] = my_lmax\n",
    "            N = 2 * (my_lmax + 1)\n",
    "            npoints[i] = N * 2*N\n",
    "        else:\n",
    "            lmax[i] = lmax_r\n",
    "            npoints[i] = npoints_r\n",
    "\n",
    "    return npoints, lmax\n",
    "\n",
    "# get quantities on a shell from the moments data\n",
    "def shellDerive(dump, r_onShell):\n",
    "    \"\"\"\n",
    "\n",
    "    dump: an integer for the dump number to be read in\n",
    "    r_onShell: the radius grid with which I interpolate quantities to\n",
    "    \"\"\"\n",
    "    # for this dump, get ur and rho on the grid\n",
    "    ur_grid = hydro.moms.get_spherical_components('ux', 'uy', 'uz', dump)[0]\n",
    "\n",
    "    # get rprof quantities used later\n",
    "    r_rprof = hydro.rprof.get('R', fname=dump, resolution='l')\n",
    "    ut_rprof = hydro.rprof.get('|Ut|', fname=dump, resolution='l')\n",
    "    rho_rprof = hydro.rprof.get('Rho0', fname=dump, resolution='l') + hydro.rprof.get('Rho1', fname=dump, resolution='l')\n",
    "    v_rprof = np.sqrt(np.power(hydro.rprof.get('|U|', fname=dump),2.0) - \n",
    "                      np.power(hydro.rprof.get('|Ut|', fname=dump), 2.0))\n",
    "    \n",
    "    rho_onShell = ppm.interpolate(r_rprof, rho_rprof, r_onShell)\n",
    "    Avgv_onShell = ppm.interpolate(r_rprof, v_rprof, r_onShell)\n",
    "    \n",
    "    # to loop through CENTRAL quantities\n",
    "    r_central = (r_onShell + np.roll(r_onShell, -1))[0:-1]/2.\n",
    "    ut_central = ppm.interpolate(r_rprof, ut_rprof, r_central)\n",
    "    dt_horizontal = np.zeros((len(power_func), len(r_central)))\n",
    "    gamma = np.zeros((len(power_func), len(r_onShell)))\n",
    "\n",
    "    # get the npoints at each radii as well as lmax\n",
    "    npoints, lmax = shellNpoints(r_onShell)\n",
    "\n",
    "    # loop through every CENTRAL radii to get the derived CENTRAL quantities\n",
    "    for count, r, lmax_r, ut_r, npoints_r in zip(np.arange(len(r_central)), r_central, lmax,\n",
    "                                                 ut_central, npoints):\n",
    "        # GAMMA QUANTITIES\n",
    "\n",
    "        # first get the properly formatted interpolation of ur, then get powerSpectrum\n",
    "        ur_formatted = hydro.moms.sphericalHarmonics_format(ur_grid, r, fname=dump, lmax=lmax_r)\n",
    "        coeffs_ur = pyshtools.expand.SHExpandDH(ur_formatted, sampling=2)\n",
    "\n",
    "        # drop l=0\n",
    "        power_ur = pyshtools.spectralanalysis.spectrum(coeffs_ur, unit='per_l')[1:]\n",
    "        \n",
    "        # for every power_func we get the appropriate dt_horizontal\n",
    "        for i, function in enumerate(power_func):\n",
    "            dt_horizontal[i, count] = function(power_ur, ut_r, r, **power_func_kwargs[i])\n",
    "\n",
    "    # DERIVE GAMMA MASS FLUX\n",
    "    # first get the mass transport. This is ALWAYS choosing the \"top shell\" as it is\n",
    "    # inherently a \"central\" quantity, mass is flowing out through the top of the shell,  but I am\n",
    "    # deriving it on shells. This means the first index is ENTIRELY WRONG (I WOULD NEVER USE IT ANYWAYS)\n",
    "    dmdt_radial = 2 * np.pi * (r_onShell**2 * rho_onShell * Avgv_onShell)[1:]\n",
    "\n",
    "    # get the radial mixing timescale, although inherently a \"central\" quantity I will roll it to\n",
    "    # get quantity on the shells. Because of above, I will ensure that the first index is\n",
    "    # ENTIRELY WRONG (I WOULD NEVER USE IT ANYWAYS)\n",
    "    dt_radial = np.diff(r_onShell) / (Avgv_onShell[1:])\n",
    "\n",
    "    # Gamma is a central quantity with its factor on the \"lower shell\" dictating the horizontal\n",
    "    # mass transfer of that cell. So, the last radii of gamma is always zero!\n",
    "    gamma[:, 0:-1] = np.abs(dmdt_radial[np.newaxis, :] * (dt_radial[np.newaxis, :] / dt_horizontal))\n",
    "\n",
    "    # shell quantities\n",
    "    return gamma, dt_radial, dt_horizontal\n",
    "\n",
    "############################################################################################\n",
    "#\n",
    "# GAMMA FUNCTIONS\n",
    "#\n",
    "############################################################################################\n",
    "\n",
    "def gamma_weightedPower(power_ur, ut_r, r, factor=None):\n",
    "\n",
    "    # first we smooth the profile\n",
    "    smooth = 5\n",
    "    smoothed_power_ur = np.convolve(power_ur, np.ones((smooth,))/smooth, mode='same')\n",
    "\n",
    "    # find index of max power if factor != 0\n",
    "    if factor is None:\n",
    "        max_i = len(power_ur) - 1\n",
    "        max_l = len(power_ur)\n",
    "\n",
    "    else:\n",
    "        max_i = np.argmin(abs(np.max(smoothed_power_ur) * factor - power_ur))\n",
    "        max_l = max_i + 1\n",
    "\n",
    "    # collect the weights up to max_i\n",
    "    weights = power_ur[0:max_i+1] / np.sum(power_ur[0:max_i+1])\n",
    "\n",
    "    # what is the timescale?\n",
    "    l = np.arange(1, max_l+1)\n",
    "    wave_by_2 = np.pi * r / np.sqrt(l * (l + 1))\n",
    "    dt_per_l = wave_by_2 / ut_r\n",
    "    dt = np.sum(weights * dt_per_l)\n",
    "    \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run and other Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomicnoH = 1.\n",
    "atomicnoC12 = 12.\n",
    "atomicnocld = n15.rprof.get('atomicnocld',fname=0)\n",
    "atomicnoair = n15.rprof.get('atomicnoair',fname=0)\n",
    "fkcld = n15.rprof.get('fkcld',fname=0)\n",
    "fkair = n15.rprof.get('fkair',fname=0)\n",
    "cldmu = n15.rprof.get('cldmu',fname=0)\n",
    "airmu = n15.rprof.get('airmu',fname=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything should be done at a single dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 768 and 1536 should be the same time but...\n",
    "n16_dump0 = 650\n",
    "n16_time0 = n16.rprof.get('t',n16_dump0)\n",
    "\n",
    "# i will construct the time arrays, history is wrong!\n",
    "n17_dumps = np.array(n17.rprof.get_dump_list())\n",
    "n16_dumps = np.array(n16.rprof.get_dump_list())\n",
    "n15_dumps = np.array(n15.rprof.get_dump_list())\n",
    "n17_times = np.zeros(len(n17_dumps))\n",
    "n16_times = np.zeros(len(n16_dumps))\n",
    "n15_times = np.zeros(len(n15_dumps))\n",
    "\n",
    "for i,dump in enumerate(n17_dumps):\n",
    "    n17_times[i] = n17.rprof.get('t',dump)\n",
    "    \n",
    "for i,dump in enumerate(n16_dumps):\n",
    "    n16_times[i] = n16.rprof.get('t',dump)\n",
    "    \n",
    "for i,dump in enumerate(n15_dumps):\n",
    "    n15_times[i] = n15.rprof.get('t',dump)\n",
    "    \n",
    "# now find what the appropriate time and dump 768 is\n",
    "dumpi = np.argmin(abs(n16_time0 - n15_times))\n",
    "n15_dump0 = n16_dumps[dumpi]\n",
    "n15_time0 = n15_times[dumpi]\n",
    "\n",
    "dumpi = np.argmin(abs(n16_time0 - n17_times))\n",
    "n17_dump0 = n16_dumps[dumpi]\n",
    "n17_time0 = n17_times[dumpi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing that the runs have been done for longer, there are some forced dumpMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n15_dumpMax = n15_dumps[-1]\n",
    "n16_dumpMax = n16_dumps[-1]\n",
    "n17_dumpMax = n17_dumps[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the dump0 and time0 for the python simulation runs for post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the initbase, i.e reading in the run files\n",
    "base = '/data/ASDR/PPMstar/3d1d-advection/N15_shell_files'\n",
    "n15_initbase = os.path.join(base, 'N15-standard-mppnp', 'N15-standard-mppnp')\n",
    "data, header = readSCFile(n15_initbase, 'shell', 100)\n",
    "\n",
    "# grab the dump quantities\n",
    "n15_simDump0 = header['runDump']\n",
    "n15_simTime0 = n15_times[n15_simDump0]\n",
    "n15_simDumpMax = len([afile for afile in os.listdir(os.path.dirname(n15_initbase)) \n",
    "                      if os.path.isfile(os.path.join(os.path.dirname(n15_initbase), afile))]) - 1 + n15_simDump0\n",
    "\n",
    "# get the mass coordinates of the boundary\n",
    "n15_mbot = data['m'][0]\n",
    "n15_mtop = data['m'][-1]\n",
    "\n",
    "# set the initbase, i.e reading in the run files\n",
    "base = '/data/ASDR/PPMstar/3d1d-advection/N16_shell_files'\n",
    "n16_initbase = os.path.join(base, 'N16-standard-mppnp', 'N16-standard-mppnp')\n",
    "data, header = readSCFile(n16_initbase, 'shell', 100)\n",
    "\n",
    "# grab the dump quantities\n",
    "n16_simDump0 = header['runDump']\n",
    "n16_simTime0 = n16_times[n16_simDump0]\n",
    "n16_simDumpMax = len([afile for afile in os.listdir(os.path.dirname(n16_initbase)) \n",
    "                      if os.path.isfile(os.path.join(os.path.dirname(n16_initbase), afile))]) - 1 + n16_simDump0\n",
    "\n",
    "# get the mass coordinates of the boundary\n",
    "n16_mbot = data['m'][0]\n",
    "n16_mtop = data['m'][-1]\n",
    "\n",
    "# set the initbase, i.e reading in the run files\n",
    "base = '/data/ASDR/PPMstar/3d1d-advection/N17_shell_files'\n",
    "n17_initbase = os.path.join(base, 'N17-standard-mppnp', 'N17-standard-mppnp')\n",
    "data, header = readSCFile(n17_initbase, 'shell', 100)\n",
    "\n",
    "# grab the dump quantities\n",
    "n17_simDump0 = header['runDump']\n",
    "n17_simTime0 = n17_times[n17_simDump0]\n",
    "n17_simDumpMax = len([afile for afile in os.listdir(os.path.dirname(n17_initbase)) \n",
    "                      if os.path.isfile(os.path.join(os.path.dirname(n17_initbase), afile))]) - 1 + n17_simDump0\n",
    "\n",
    "# get the mass coordinates of the boundary\n",
    "n17_mbot = data['m'][0]\n",
    "n17_mtop = data['m'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after calculating everything else for the named tuple, set them\n",
    "n15 = n15._replace(dump0=n15_dump0, time0=n15_time0, dumpMax=n15_dumpMax, dumps=n15_dumps, times=n15_times, \n",
    "                  initbase=n15_initbase, simDump0=n15_simDump0, simTime0=n15_simTime0, \n",
    "                  simDumpMax=n15_simDumpMax, mbot=n15_mbot, mtop=n15_mtop)\n",
    "\n",
    "n16 = n16._replace(dump0=n16_dump0, time0=n16_time0, dumpMax=n16_dumpMax, dumps=n16_dumps, times=n16_times, \n",
    "                  initbase=n16_initbase, simDump0=n16_simDump0, simTime0=n16_simTime0, \n",
    "                  simDumpMax=n16_simDumpMax, mbot=n16_mbot, mtop=n16_mtop)\n",
    "\n",
    "n17 = n17._replace(dump0=n17_dump0, time0=n17_time0, dumpMax=n17_dumpMax, dumps=n17_dumps, times=n17_times, \n",
    "                  initbase=n17_initbase, simDump0=n17_simDump0, simTime0=n17_simTime0, \n",
    "                  simDumpMax=n17_simDumpMax, mbot=n17_mbot, mtop=n17_mtop)\n",
    "\n",
    "# master dictionary\n",
    "run = collections.OrderedDict(zip(runs, [n15, n16, n17]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radial Profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showcase the radial profiles of the radial, tangential and total velocity. Also show the heating region of PPMStar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heating region constants\n",
    "radbase = 7.282\n",
    "dlayerbot = 2.0\n",
    "\n",
    "rminbase = radbase + .5 * dlayerbot\n",
    "rmaxbase = radbase + 1.5 * dlayerbot\n",
    "\n",
    "# dictionaries for run specific quantities\n",
    "initbase = collections.OrderedDict((run, []) for run in runs)\n",
    "ur = collections.OrderedDict((run, []) for run in runs)\n",
    "ur_rms = collections.OrderedDict((run, []) for run in runs)\n",
    "ut = collections.OrderedDict((run, []) for run in runs)\n",
    "ut_gosh = collections.OrderedDict((run, []) for run in runs)\n",
    "u = collections.OrderedDict((run, []) for run in runs)\n",
    "r = collections.OrderedDict((run, []) for run in runs)\n",
    "r_stream = collections.OrderedDict((run, []) for run in runs)\n",
    "dumpStart = collections.OrderedDict((run, []) for run in runs)\n",
    "dumpEnd = collections.OrderedDict((run, []) for run in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the different runs\n",
    "for runstr, myrun in run.items():\n",
    "        \n",
    "    # velocities from rprofs\n",
    "    u[runstr] = myrun.rprof.get('|U|',fname=myrun.dump0)\n",
    "    ut[runstr] = myrun.rprof.get('|Ut|',fname=myrun.dump0)\n",
    "    ur[runstr] = myrun.rprof.get('Ur',fname=myrun.dump0)\n",
    "    ur_rms[runstr] = np.sqrt(np.power(u[runstr],2.0) - np.power(ut[runstr],2.0))\n",
    "    r[runstr] = myrun.rprof.get('R',fname=myrun.dump0,resolution='l')\n",
    "    \n",
    "    # convert velocities to km/s\n",
    "    u[runstr] *= 1e3\n",
    "    ut[runstr] *= 1e3\n",
    "    ur[runstr] *= 1e3\n",
    "    ur_rms[runstr] *= 1e3\n",
    "    \n",
    "# loop through the dumps of each run and determine average ut for detecting GOSH\n",
    "avg_offset = 1\n",
    "avg_zone = 1\n",
    "\n",
    "for runstr, myrun in run.items():\n",
    "    \n",
    "    # dumps to use\n",
    "    dumpStart[runstr] = myrun.simDump0\n",
    "    dumpEnd[runstr] = myrun.dumpMax\n",
    "    \n",
    "    alldumps = list(range(dumpStart[runstr], dumpEnd[runstr]))\n",
    "    \n",
    "    # initialize array to hold averages\n",
    "    ut_gosh[runstr] = np.zeros(len(alldumps))\n",
    "    \n",
    "    # for every dump to analyze\n",
    "    for dump in alldumps:\n",
    "            \n",
    "        # grab ut and r\n",
    "        ut_dump = myrun.rprof.get('|Ut|',fname=dump)\n",
    "        ut_dump[np.isnan(ut_dump)] = 0.\n",
    "        ut_dump *= 1e3\n",
    "        r_dump = myrun.rprof.get('R',fname=dump)\n",
    "        \n",
    "        # determine the upper boundary\n",
    "        rtop = m2r(myrun.mtop, myrun, dump)\n",
    "        rtop_avg = rtop - avg_offset\n",
    "        rbot_avg = rtop_avg - avg_zone\n",
    "        \n",
    "        # find indices for the averaging\n",
    "        avg_indices = ((r_dump > rbot_avg) & (r_dump < rtop_avg))\n",
    "        ut_gosh[runstr][dump-alldumps[0]] = ut_dump[avg_indices].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vrprofs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot dependent dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which ones to use\n",
    "run_plots = ['n15', 'n16']\n",
    "\n",
    "# boundaries, etc.\n",
    "myylim = [0,30]\n",
    "myxlim = [5,30]\n",
    "rtop = m2r(run['n16'].mtop, run['n16'], run['n16'].dump0)\n",
    "rbot = m2r(run['n16'].mbot, run['n16'], run['n16'].dump0)\n",
    "\n",
    "# plot stuff\n",
    "savefig = 'vrprofs.pdf'\n",
    "render = True\n",
    "save = True\n",
    "thickline = 1.5\n",
    "thinline = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = -1\n",
    "\n",
    "# celln\n",
    "celln += 1\n",
    "\n",
    "# configure plots\n",
    "close_local = ppm.close_plot(celln,ifig,ptrack)\n",
    "if close_local[0]:\n",
    "    plt.close(fig); ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "    ppm.add_plot(celln,ifig,ptrack)\n",
    "else:\n",
    "    ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "    ppm.add_plot(celln,ifig,ptrack)\n",
    "\n",
    "# use the same color scheme for plots\n",
    "cbc = 0\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for runstr, myrun in run.items():\n",
    "    if runstr not in run_plots:\n",
    "        continue\n",
    "        \n",
    "    if runstr == 'n16':\n",
    "        ax.plot(r[runstr],ur_rms[runstr],ls=cb(cbc)[0],color=cb(cbc)[2],label=r'v$_{r}$',\n",
    "               linewidth=thickline)\n",
    "    else:\n",
    "        ax.plot(r[runstr],ur_rms[runstr],ls=cb(cbc)[0],color=cb(cbc)[2],linewidth=thinline)\n",
    "cbc += 1\n",
    "\n",
    "# loop through the different runs\n",
    "for runstr, myrun in run.items():\n",
    "    if runstr not in run_plots:\n",
    "        continue\n",
    "        \n",
    "    if runstr == 'n16':\n",
    "        ax.plot(r[runstr],ut[runstr],ls=cb(cbc)[0],color=cb(cbc)[2],\n",
    "                label=r'v$_{\\perp}$',linewidth=thickline)\n",
    "    else:\n",
    "        ax.plot(r[runstr],ut[runstr],ls=cb(cbc)[0],color=cb(cbc)[2],linewidth=thinline)\n",
    "cbc += 1\n",
    "\n",
    "# loop through the different runs\n",
    "for runstr, myrun in run.items():\n",
    "    if runstr not in run_plots:\n",
    "        continue\n",
    "        \n",
    "    if runstr == 'n16':\n",
    "        ax.plot(r[runstr],u[runstr],ls=cb(cbc+1)[0],color=cb(cbc)[2],label=r'v',\n",
    "               linewidth=thickline)\n",
    "    else:\n",
    "        ax.plot(r[runstr],u[runstr],ls=cb(cbc+1)[0],color=cb(cbc)[2],linewidth=thinline)\n",
    "cbc += 1\n",
    "\n",
    "# add a shaded rectangle\n",
    "ax.add_patch(patches.Rectangle((rminbase,myylim[0]),rmaxbase - rminbase,myylim[-1] - myylim[0],facecolor='blanchedalmond'))\n",
    "\n",
    "# add the convective boundary lines\n",
    "ax.vlines(rtop, *myylim, color='k', linestyle=':')\n",
    "ax.vlines(rbot, *myylim, color='k', linestyle=':')\n",
    "\n",
    "# plot details\n",
    "ax.set_xlabel('r / Mm')\n",
    "ax.set_ylabel(r'v$_{\\mathrm{rms}}$ / km s$^{-1}$')\n",
    "ax.set_ylim(myylim)\n",
    "ax.set_xlim(myxlim)\n",
    "ax.legend(frameon=False, loc='lower center')\n",
    "\n",
    "# savefig\n",
    "fig.tight_layout()\n",
    "if save:\n",
    "    fig.savefig(savefig,bbox_inches = \"tight\",dpi=300)\n",
    "if not render:\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ut averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boundaries, etc.\n",
    "myylim = [0,200]\n",
    "myxlim = [300,800]\n",
    "thinline = 1.0\n",
    "\n",
    "# plot stuff\n",
    "savefig = 'gosh_rprofs.pdf'\n",
    "render = True\n",
    "save = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 200\n",
    "\n",
    "# celln\n",
    "celln += 1\n",
    "\n",
    "# configure plots\n",
    "close_local = ppm.close_plot(celln,ifig,ptrack)\n",
    "if close_local[0]:\n",
    "    plt.close(fig); ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "    ppm.add_plot(celln,ifig,ptrack)\n",
    "else:\n",
    "    ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "    ppm.add_plot(celln,ifig,ptrack)\n",
    "\n",
    "# use the same color scheme for plots\n",
    "cbc = 0\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# loop through the different runs\n",
    "for runstr, myrun in run.items():\n",
    "    ax.plot(myrun.times[myrun.simDump0:myrun.dumpMax] / 60., ut_gosh[runstr], color=cb(cbc)[2],\n",
    "            label=runstr.capitalize(),linewidth=thinline)\n",
    "    cbc += 1\n",
    "\n",
    "# plot details\n",
    "ax.set_xlabel('t / min')\n",
    "ax.set_ylabel(r'$\\langle v_{\\perp, \\mathrm{rms}} \\rangle$ / km s$^{-1}$')\n",
    "ax.vlines(myrun.times[1089]/60., *myylim, color='k', linestyle='-', linewidth=0.8)\n",
    "ax.set_ylim(myylim)\n",
    "ax.set_xlim(myxlim)\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "# savefig\n",
    "fig.tight_layout()\n",
    "if save:\n",
    "    fig.savefig(savefig,bbox_inches = \"tight\",dpi=300)\n",
    "if not render:\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mollweide Plots (Fig 4, 7 & 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showcase the radial velocity and XH close to the middle of the convection zone and near the upper boundary. This is to show the changing scales of the flows and how isolated/homogenized the streams are at different radii. The images must be rasterized otherwise they are huge files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other constants\n",
    "radii_low = 14.5\n",
    "radii_high = 23\n",
    "radii_iter = collections.OrderedDict(zip(['low','high'],[radii_low, radii_high]))\n",
    "\n",
    "# dictionary run and radii quantities\n",
    "ur_r = collections.OrderedDict((run, \n",
    "                                collections.OrderedDict(zip(radii_iter.keys(), \n",
    "                                                            [1]*len(radii_iter.keys())))) for run in runs)\n",
    "XH_r = collections.OrderedDict((run, \n",
    "                                collections.OrderedDict(zip(radii_iter.keys(), \n",
    "                                                            [1]*len(radii_iter.keys())))) for run in runs)\n",
    "utheta_r = collections.OrderedDict((run, \n",
    "                                collections.OrderedDict(zip(radii_iter.keys(), \n",
    "                                                            [1]*len(radii_iter.keys())))) for run in runs)\n",
    "rhoFluct_r = collections.OrderedDict((run, \n",
    "                                collections.OrderedDict(zip(radii_iter.keys(), \n",
    "                                                            [1]*len(radii_iter.keys())))) for run in runs)\n",
    "rhour_r = collections.OrderedDict((run, \n",
    "                                collections.OrderedDict(zip(radii_iter.keys(), \n",
    "                                                            [1]*len(radii_iter.keys())))) for run in runs)\n",
    "npoints = collections.OrderedDict((run, \n",
    "                                collections.OrderedDict(zip(radii_iter.keys(), \n",
    "                                                            [1]*len(radii_iter.keys())))) for run in runs)\n",
    "phi_r = collections.OrderedDict((run, \n",
    "                                collections.OrderedDict(zip(radii_iter.keys(), \n",
    "                                                            [1]*len(radii_iter.keys())))) for run in runs)\n",
    "theta_r = collections.OrderedDict((run, \n",
    "                                collections.OrderedDict(zip(radii_iter.keys(), \n",
    "                                                            [1]*len(radii_iter.keys())))) for run in runs)\n",
    "radii_fluxFA = collections.OrderedDict((run, \n",
    "                                collections.OrderedDict(zip(radii_iter.keys(), \n",
    "                                                            [1]*len(radii_iter.keys())))) for run in runs) \n",
    "flux_up = collections.OrderedDict((run, \n",
    "                                collections.OrderedDict(zip(radii_iter.keys(), \n",
    "                                                            [1]*len(radii_iter.keys())))) for run in runs)\n",
    "FA_up = collections.OrderedDict((run, \n",
    "                                collections.OrderedDict(zip(radii_iter.keys(), \n",
    "                                                            [1]*len(radii_iter.keys())))) for run in runs)\n",
    "\n",
    "# only run dependent quantities\n",
    "utr_bound = collections.OrderedDict((run, [1]*len(runs)) for run in runs)\n",
    "XH_avg_U = collections.OrderedDict((run, [1]*len(runs)) for run in runs)\n",
    "XH_avg_D = collections.OrderedDict((run, [1]*len(runs)) for run in runs)\n",
    "r_stream = collections.OrderedDict((run, [1]*len(runs)) for run in runs)\n",
    "\n",
    "npoints_ut_boundary = collections.OrderedDict((run, [1]*len(runs)) for run in runs)\n",
    "phi_ut_boundary = collections.OrderedDict((run, [1]*len(runs)) for run in runs)\n",
    "theta_ut_boundary = collections.OrderedDict((run, [1]*len(runs)) for run in runs)\n",
    "\n",
    "# calculate the number of points to sample properly at select radii\n",
    "for runstr, myrun in run.items():\n",
    "    for radstr, radius in radii_iter.items():\n",
    "        npoints[runstr][radstr] = myrun.moms.sphericalHarmonics_lmax(radius)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get quantities on a sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the different runs\n",
    "for runstr, myrun in run.items():\n",
    "   \n",
    "    # radii counter\n",
    "    i = 0\n",
    "    \n",
    "    # grab the low and high radial velocities and XH\n",
    "    for radstr, radius in radii_iter.items():\n",
    "           \n",
    "        # get the radial and tangential velocity component\n",
    "        ur, utheta, uphi = myrun.moms.get_spherical_components('ux','uy','uz',fname=myrun.dump0)     \n",
    "        tur_r, ttheta_r, tphi_r = myrun.moms.get_spherical_interpolation(ur,radius,fname=myrun.dump0,\n",
    "                                                                        npoints=npoints[runstr][radstr],\n",
    "                                                                        plot_mollweide=True)\n",
    "        \n",
    "        ur_r[runstr][radstr] = tur_r\n",
    "        theta_r[runstr][radstr] = ttheta_r\n",
    "        phi_r[runstr][radstr] = tphi_r\n",
    "        \n",
    "        utheta = myrun.moms.get('|ut|',fname=myrun.dump0)\n",
    "        tutheta_r = myrun.moms.get_spherical_interpolation(utheta,radius,fname=myrun.dump0,\n",
    "                                                          npoints=npoints[runstr][radstr])\n",
    "        \n",
    "        utheta_r[runstr][radstr] = tutheta_r\n",
    "        \n",
    "        # get the mass fraction of H\n",
    "        fv = myrun.moms.get('fv',fname=myrun.dump0)\n",
    "        \n",
    "        # this is Xcld\n",
    "        Xcld = fv/((1. - fv)*(airmu/cldmu) + fv)\n",
    "        \n",
    "        # convert to XH\n",
    "        XH = Xcld * fkcld * atomicnoH / atomicnocld\n",
    "        \n",
    "        # get it on the sphere\n",
    "        XH_r[runstr][radstr] = myrun.moms.get_spherical_interpolation(XH,radius,fname=myrun.dump0,\n",
    "                                                                  npoints=npoints[runstr][radstr])\n",
    "        \n",
    "        # get the density fluctuations on the sphere\n",
    "        rho = myrun.moms.get('rho',myrun.dump0)\n",
    "        rho_r = myrun.moms.get_spherical_interpolation(rho,radius,fname=myrun.dump0,\n",
    "                                                method='moments', npoints=npoints[runstr][radstr])\n",
    "        rhoFluct_r[runstr][radstr] = (rho_r - rho_r.mean()) / rho_r.mean()\n",
    "        \n",
    "        # get the mass flux on the sphere\n",
    "        rhour = rho * ur\n",
    "        rhour_r[runstr][radstr] = myrun.moms.get_spherical_interpolation(rhour,radius,fname=myrun.dump0,\n",
    "                                                                npoints=npoints[runstr][radstr])\n",
    "        \n",
    "        # increment radii counter\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work out the convective boundary from utheta condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factor\n",
    "factor = 5.\n",
    "\n",
    "# loop through the different runs\n",
    "for runstr, myrun in run.items():\n",
    "    \n",
    "    # get the tangential velocity\n",
    "#     ur, utheta, uphi = myrun.moms.get_spherical_components('ux','uy','uz',fname=myrun.dump0)\n",
    "    utheta = myrun.moms.get('|ut|',fname=myrun.dump0)\n",
    "    \n",
    "    # create a radial axis for the utr_r rays, only near the convective boundary\n",
    "    rbot_ut = 22\n",
    "    rtop_ut = 28\n",
    "    deex = myrun.moms.moms_gridresolution\n",
    "    radial_axis = np.arange(0, int(factor*(rtop_ut - rbot_ut)/deex)) * (deex/factor) + rbot_ut\n",
    "    \n",
    "    # get the gradient on the sphere\n",
    "    npoints_ut_boundary[runstr] = 100000\n",
    "    ut_r, theta_ut_boundary[runstr], phi_ut_boundary[runstr] = myrun.moms.get_spherical_interpolation(\n",
    "        utheta,radial_axis,fname=myrun.dump0,npoints=npoints_ut_boundary[runstr],plot_mollweide=True,method='trilinear')\n",
    "    \n",
    "    # smooth parameter\n",
    "    N = 7\n",
    "    utr_r = np.zeros(ut_r.shape)\n",
    "    for point in range(ut_r.shape[1]):\n",
    "        \n",
    "        # smooth before derivative\n",
    "        utr_r[:,point] = np.convolve(utr_r[:,point], np.ones((N,))/N, mode='same')\n",
    "        utr_r[:,point] = ppm.cdiff(ut_r[:,point]) / ppm.cdiff(radial_axis)\n",
    "        \n",
    "    # create the zeros array for the boundary\n",
    "    utr_bound[runstr] = np.zeros(utr_r.shape[1])\n",
    "    \n",
    "    # loop over the npoints, find the minimum\n",
    "    for point in range(utr_r.shape[1]):\n",
    "        min_utr = np.argmin(utr_r[:,point])\n",
    "        utr_bound[runstr][point] = radial_axis[min_utr]\n",
    "        \n",
    "    print('Done {:s}'.format(runstr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the percent of the mass flux in the up and down directions at the two radii? What is their fractional areas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs to calculate, this one takes a bit\n",
    "runs_calc = ['n16']\n",
    "\n",
    "# loop through the different runs\n",
    "for runstr, myrun in run.items():\n",
    "    \n",
    "    # are we working with every run?\n",
    "    if runstr not in runs_calc:\n",
    "        continue\n",
    "        \n",
    "    # what radii for this run?\n",
    "    min_r = m2r(myrun.mbot, myrun, myrun.dump0)\n",
    "    max_r = m2r(myrun.mtop, myrun, myrun.dump0)\n",
    "    deex = myrun.rprof.get('deex',0)\n",
    "    radii_fluxFA[runstr] = np.linspace(min_r, max_r, int((max_r - min_r)/deex))\n",
    "    \n",
    "    FA_up[runstr] = np.zeros(len(radii_fluxFA[runstr]))\n",
    "    flux_up[runstr] = np.zeros(len(radii_fluxFA[runstr]))\n",
    "    \n",
    "    # my radial velocity grid\n",
    "    ur, utheta, uphi = myrun.moms.get_spherical_components('ux','uy','uz',fname=myrun.dump0)\n",
    "    rho = myrun.moms.get('rho',fname=myrun.dump0)\n",
    "    \n",
    "    # loop through the radii\n",
    "    for counter, radius in enumerate(radii_fluxFA[runstr]):\n",
    "    \n",
    "        # how many points to sample\n",
    "        npoints = myrun.moms.sphericalHarmonics_lmax(radius)[2]\n",
    "        \n",
    "        # get the radial velocity on the sphere    \n",
    "        tur_r = myrun.moms.get_spherical_interpolation(ur,radius,fname=myrun.dump0,\n",
    "                                                                        npoints=npoints,\n",
    "                                                                        plot_mollweide=False)\n",
    "        trho_r = myrun.moms.get_spherical_interpolation(rho,radius,fname=myrun.dump0,\n",
    "                                                                        npoints=npoints,\n",
    "                                                                        plot_mollweide=False)\n",
    "        \n",
    "        # FA and flux\n",
    "        positive_v = (tur_r > 0)\n",
    "        \n",
    "        FA_up[runstr][counter] = np.count_nonzero(positive_v) / npoints\n",
    "        flux_up[runstr][counter] = (tur_r * trho_r)[positive_v].sum() / (np.abs(tur_r * trho_r).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the up and down stream averages for the H mass fraction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ur Mollweide Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot dependent dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if i want to look at one particular run and/or radii\n",
    "runs_plot = ['n16']\n",
    "radii_plot = ['low', 'high']\n",
    "gridlines = 0.1\n",
    "\n",
    "# plot stuff\n",
    "savefig = collections.OrderedDict((run, \n",
    "                                collections.OrderedDict(zip(radii_iter.keys(), \n",
    "                                                            [1]*len(radii_iter.keys())))) for run in runs)\n",
    "\n",
    "savefig['n15']['low'] = 'N15-vr-mollweide-low.pdf'\n",
    "savefig['n15']['high'] = 'N15-vr-mollweide-high.pdf'\n",
    "savefig['n16']['low'] = 'N16-vr-mollweide-low.pdf'\n",
    "savefig['n16']['high'] = 'N16-vr-mollweide-high.pdf'\n",
    "savefig['n17']['low'] = 'N17-vr-mollweide-low.pdf'\n",
    "savefig['n17']['high'] = 'N17-vr-mollweide-high.pdf'\n",
    "render = True\n",
    "save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 0\n",
    "\n",
    "# loop through every run\n",
    "for runstr, myrun in run.items():\n",
    "    \n",
    "    # loop through the radii\n",
    "    for radstr, radius in radii_iter.items():\n",
    "\n",
    "        # are we working with every run?\n",
    "        if runstr not in runs_plot:\n",
    "            continue\n",
    "\n",
    "        # are we working with every radius?\n",
    "        if radstr not in radii_plot:\n",
    "            continue\n",
    "            \n",
    "        # celln\n",
    "        celln += 1\n",
    "\n",
    "        # configure plots\n",
    "        close_local = ppm.close_plot(celln,ifig,ptrack)\n",
    "        if close_local[0]:\n",
    "            plt.close(fig); ifig += 1; fig = plt.figure(ifig,figsize=(mollSize*mollRatio,mollSize),dpi=300)\n",
    "            ppm.add_plot(celln,ifig,ptrack)\n",
    "        else:\n",
    "            ifig += 1; fig = plt.figure(ifig,figsize=(mollSize*mollRatio,mollSize),dpi=300)\n",
    "            ppm.add_plot(celln,ifig,ptrack)\n",
    "\n",
    "        ax = plt.axes([0.01, 0.01, 0.98, 0.88], projection='mollweide')\n",
    "     \n",
    "        # convert units to km/s\n",
    "        ur_plot = ur_r[runstr][radstr] * 1e3\n",
    "        \n",
    "        # if it is the higher radius, velocities are smaller and homogenized, use std\n",
    "        if radstr == 'high':   \n",
    "            # find the vmin/vmax\n",
    "            vval = np.abs(ur_plot).mean() + 5*np.abs(ur_plot).std()\n",
    "            \n",
    "            ax.scatter(phi_r[runstr][radstr], theta_r[runstr][radstr], s=(72./fig.dpi)**2, \n",
    "                       marker=',',c=ur_plot,cmap='RdBu_r',vmin=-vval, vmax=vval,rasterized=True)\n",
    "        else:\n",
    "            # find the vmin/vmax\n",
    "            vval = np.max(np.abs(ur_plot))\n",
    "\n",
    "            # plot\n",
    "            ax.scatter(phi_r[runstr][radstr], theta_r[runstr][radstr], s=(72./fig.dpi)**2, \n",
    "                         marker=',',c=ur_plot,cmap='RdBu_r',vmin=-vval,vmax=vval,rasterized=True)\n",
    "                       \n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.grid(color='k', linewidth=gridlines)\n",
    "\n",
    "        # create a colorbar for the axs1 tripcolor, use a new axes for it\n",
    "        cax = fig.add_axes([0.01, 0.03, 0.98, 0.03])\n",
    "        cbar1 = fig.colorbar(ax.collections[0], cax=cax, orientation='horizontal',format='%.1f',\n",
    "                             label=r'v$_{\\mathrm{r}}$  / km s$^{-1}$')\n",
    "        \n",
    "        # savefig\n",
    "        if save:\n",
    "            fig.savefig(savefig[runstr][radstr],bbox_inches = \"tight\",dpi=300)\n",
    "        if not render:\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XH Mollweide Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot dependent dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if i want to look at one particular run and/or radii\n",
    "runs_plot = ['n16']\n",
    "radii_plot = ['low', 'high']\n",
    "gridlines = 0.1\n",
    "\n",
    "# plot stuff\n",
    "savefig = collections.OrderedDict((run, \n",
    "                                collections.OrderedDict(zip(radii_iter.keys(), \n",
    "                                                            [1]*len(radii_iter.keys())))) for run in runs)\n",
    "\n",
    "savefig['n15']['low'] = 'N15-XH-mollweide-low.pdf'\n",
    "savefig['n15']['high'] = 'N15-XH-mollweide-high.pdf'\n",
    "savefig['n16']['low'] = 'N16-XH-mollweide-low.pdf'\n",
    "savefig['n16']['high'] = 'N16-XH-mollweide-high.pdf'\n",
    "savefig['n17']['low'] = 'N17-XH-mollweide-low.pdf'\n",
    "savefig['n17']['high'] = 'N17-XH-mollweide-high.pdf'\n",
    "render = True\n",
    "save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mollRatio = 3.5/2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 4\n",
    "\n",
    "# loop through every run\n",
    "for runstr, myrun in run.items():\n",
    "\n",
    "    # are we working with every run?\n",
    "    if runstr not in runs_plot:\n",
    "        continue\n",
    "        \n",
    "    # loop through the radii\n",
    "    for radstr, radius in radii_iter.items():    \n",
    "\n",
    "        # are we working with every run?\n",
    "        if radstr not in radii_plot:\n",
    "            continue\n",
    "        \n",
    "        # celln\n",
    "        celln += 1\n",
    "\n",
    "        # configure plots\n",
    "        close_local = ppm.close_plot(celln,ifig,ptrack)\n",
    "        if close_local[0]:\n",
    "            plt.close(fig); ifig += 1; fig = plt.figure(ifig,figsize=(mollSize*mollRatio,mollSize),dpi=300)\n",
    "            ppm.add_plot(celln,ifig,ptrack)\n",
    "        else:\n",
    "            ifig += 1; fig = plt.figure(ifig,figsize=(mollSize*mollRatio,mollSize),dpi=300)\n",
    "            ppm.add_plot(celln,ifig,ptrack)\n",
    "\n",
    "        ax = plt.axes([0.01, 0.01, 0.98, 0.88], projection='mollweide')\n",
    "     \n",
    "        # use log plot, the range of values should be the same for both in this case since it is log\n",
    "        if radstr == 'low':\n",
    "            XH_log = [1e-8, 1e-4]\n",
    "        else:\n",
    "            XH_log = [1e-8, 1e-3]\n",
    "            \n",
    "        # remove an XH below 1e-8\n",
    "        XH_plot = XH_r[runstr][radstr]\n",
    "        XH_plot[np.where(XH_plot < 1e-8)] = 0.\n",
    "        \n",
    "        # plot\n",
    "        ax.scatter(phi_r[runstr][radstr], theta_r[runstr][radstr], s=(72./fig.dpi)**2, \n",
    "                       marker=',',c=np.log10(XH_plot),cmap='Spectral_r',vmin=np.log10(min(XH_log)),\n",
    "                   vmax=np.log10(max(XH_log)),rasterized=True)\n",
    "                       \n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.grid(color='k', linewidth=gridlines)\n",
    "\n",
    "        # create a colorbar for the axs1 tripcolor, take part of the axes\n",
    "        cax = fig.add_axes([0.01, 0.03, 0.98, 0.03])\n",
    "        cbar1 = fig.colorbar(ax.collections[0], cax=cax, orientation='horizontal',format='%.1f',\n",
    "                             label=r'$\\log_{10}(\\mathrm{X}_{\\mathrm{H}}$)')\n",
    "\n",
    "        # savefig\n",
    "        if save:\n",
    "            fig.savefig(savefig[runstr][radstr],bbox_inches = \"tight\",dpi=300)\n",
    "        if not render:\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rho Mollweide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if i want to look at one particular run and/or radii\n",
    "runs_plot = ['n16']\n",
    "radii_plot = ['low', 'high']\n",
    "gridlines = 0.1\n",
    "\n",
    "# plot stuff\n",
    "savefig = collections.OrderedDict((run, \n",
    "                                collections.OrderedDict(zip(radii_iter.keys(), \n",
    "                                                            [1]*len(radii_iter.keys())))) for run in runs)\n",
    "\n",
    "savefig['n15']['low'] = 'N15-rho-mollweide-low.pdf'\n",
    "savefig['n15']['high'] = 'N15-rho-mollweide-high.pdf'\n",
    "savefig['n16']['low'] = 'N16-rho-mollweide-low.pdf'\n",
    "savefig['n16']['high'] = 'N16-rho-mollweide-high.pdf'\n",
    "savefig['n17']['low'] = 'N17-rho-mollweide-low.pdf'\n",
    "savefig['n17']['high'] = 'N17-rho-mollweide-high.pdf'\n",
    "render = True\n",
    "save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 80\n",
    "\n",
    "# loop through every run\n",
    "for runstr, myrun in run.items():\n",
    "\n",
    "    # are we working with every run?\n",
    "    if runstr not in runs_plot:\n",
    "        continue\n",
    "        \n",
    "    # loop through the radii\n",
    "    for radstr, radius in radii_iter.items():    \n",
    "\n",
    "        # are we working with every run?\n",
    "        if radstr not in radii_plot:\n",
    "            continue\n",
    "        \n",
    "        # celln\n",
    "        celln += 1\n",
    "\n",
    "        # configure plots\n",
    "        close_local = ppm.close_plot(celln,ifig,ptrack)\n",
    "        if close_local[0]:\n",
    "            plt.close(fig); ifig += 1; fig = plt.figure(ifig,figsize=(mollSize*mollRatio,mollSize),dpi=300)\n",
    "            ppm.add_plot(celln,ifig,ptrack)\n",
    "        else:\n",
    "            ifig += 1; fig = plt.figure(ifig,figsize=(mollSize*mollRatio,mollSize),dpi=300)\n",
    "            ppm.add_plot(celln,ifig,ptrack)\n",
    "\n",
    "        ax = plt.axes([0.01, 0.01, 0.98, 0.88], projection='mollweide')\n",
    "     \n",
    "        # even bounds\n",
    "        rho_plot = rhoFluct_r[runstr][radstr]\n",
    "        \n",
    "        if radstr == 'high':\n",
    "            rho_bounds = np.mean(rho_plot) + 6*np.std(rho_plot)\n",
    "        else:\n",
    "            rho_bounds = np.max(np.abs(rho_plot))\n",
    "        \n",
    "        # plot\n",
    "        ax.scatter(phi_r[runstr][radstr], theta_r[runstr][radstr], s=(72./fig.dpi)**2, \n",
    "                       marker=',',c=rho_plot,cmap='BrBG',rasterized=True,vmin=-rho_bounds,\n",
    "                   vmax=rho_bounds)\n",
    "                       \n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.grid(color='k', linewidth=gridlines)\n",
    "\n",
    "        # create a colorbar for the axs1 tripcolor, take part of the axes\n",
    "        cax = fig.add_axes([0.01, 0.03, 0.98, 0.03])\n",
    "        cbar1 = fig.colorbar(ax.collections[0], cax=cax, orientation='horizontal',format='%.0e',\n",
    "                             label=r'$\\left( \\rho - \\langle \\rho \\rangle \\right) / \\langle \\rho \\rangle$')\n",
    "\n",
    "        # savefig\n",
    "        if save:\n",
    "            fig.savefig(savefig[runstr][radstr],bbox_inches = \"tight\",dpi=300)\n",
    "        if not render:\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utheta Mollweide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if i want to look at one particular run and/or radii\n",
    "runs_plot = ['n16']\n",
    "radii_plot = ['low', 'high']\n",
    "gridlines = 0.1\n",
    "\n",
    "# plot stuff\n",
    "savefig = collections.OrderedDict((run, \n",
    "                                collections.OrderedDict(zip(radii_iter.keys(), \n",
    "                                                            [1]*len(radii_iter.keys())))) for run in runs)\n",
    "\n",
    "savefig['n15']['low'] = 'N15-vt-mollweide-low.pdf'\n",
    "savefig['n15']['high'] = 'N15-vt-mollweide-high.pdf'\n",
    "savefig['n16']['low'] = 'N16-vt-mollweide-low.pdf'\n",
    "savefig['n16']['high'] = 'N16-vt-mollweide-high.pdf'\n",
    "savefig['n17']['low'] = 'N17-vt-mollweide-low.pdf'\n",
    "savefig['n17']['high'] = 'N17-vt-mollweide-high.pdf'\n",
    "render = True\n",
    "save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 8\n",
    "\n",
    "# loop through every run\n",
    "for runstr, myrun in run.items():\n",
    "\n",
    "    # are we working with every run?\n",
    "    if runstr not in runs_plot:\n",
    "        continue\n",
    "        \n",
    "    # radii counter \n",
    "    i = 0\n",
    "    \n",
    "    # loop through the radii\n",
    "    for radstr, radius in radii_iter.items():    \n",
    "\n",
    "        # are we working with every run?\n",
    "        if radstr not in radii_plot:\n",
    "            continue\n",
    "        \n",
    "        # celln\n",
    "        celln += 1\n",
    "\n",
    "        # configure plots\n",
    "        close_local = ppm.close_plot(celln,ifig,ptrack)\n",
    "        if close_local[0]:\n",
    "            plt.close(fig); ifig += 1; fig = plt.figure(ifig,figsize=(mollSize*mollRatio,mollSize),dpi=300)\n",
    "            ppm.add_plot(celln,ifig,ptrack)\n",
    "        else:\n",
    "            ifig += 1; fig = plt.figure(ifig,figsize=(mollSize*mollRatio,mollSize),dpi=300)\n",
    "            ppm.add_plot(celln,ifig,ptrack)\n",
    "\n",
    "        ax = plt.axes([0.01, 0.01, 0.98, 0.88], projection='mollweide')\n",
    "        \n",
    "        # convert to km/s\n",
    "        utheta_plot = utheta_r[runstr][radstr] * 1e3\n",
    "        \n",
    "        # keep same colorbar limits\n",
    "        if i == 0:\n",
    "            uthmin = np.min(utheta_plot)\n",
    "            uthmax = np.max(utheta_plot)\n",
    "        \n",
    "        # plot\n",
    "        ax.scatter(phi_r[runstr][radstr], theta_r[runstr][radstr], s=(72./fig.dpi)**2, \n",
    "                       marker=',',c=utheta_plot,cmap='YlGnBu_r',vmin=uthmin,vmax=uthmax,rasterized=True)\n",
    "                       \n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.grid(color='k', linewidth=gridlines)\n",
    "\n",
    "        # create a colorbar for the axs1 tripcolor, take part of the axes\n",
    "        cax = fig.add_axes([0.01, 0.03, 0.98, 0.03])\n",
    "        cbar1 = fig.colorbar(ax.collections[0], cax=cax, orientation='horizontal',format='%.1f',\n",
    "                             label=r'$|v_{\\perp}|$ / km s$^{-1}$')\n",
    "\n",
    "        # savefig\n",
    "        if save:\n",
    "            fig.savefig(savefig[runstr][radstr],bbox_inches = \"tight\",dpi=300)\n",
    "        if not render:\n",
    "            plt.close()\n",
    "            \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utheta Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if i want to look at one particular run and/or radii\n",
    "runs_plot = ['n16']\n",
    "gridlines = 0.1\n",
    "\n",
    "def ubound(items):\n",
    "    return utr_bound[items[0]].mean() + (utr_bound[items[0]].mean() - items[1])\n",
    "\n",
    "# plot stuff\n",
    "savefig = collections.OrderedDict(zip(run.keys(), ['N15-vt-boundary.pdf', 'N16-vt-boundary.pdf',\n",
    "                                                  'N17-vt-boundary.pdf']))\n",
    "render = True\n",
    "save = True\n",
    "\n",
    "# find the boundaries that I want\n",
    "utheta_lbound = collections.OrderedDict(zip(run.keys(), [23, 23, 23]))\n",
    "utheta_ubound = collections.OrderedDict(zip(run.keys(), map(ubound, utheta_lbound.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 12\n",
    "\n",
    "# loop through every run\n",
    "for runstr, myrun in run.items():\n",
    "    \n",
    "    # are we working with every run?\n",
    "    if runstr not in runs_plot:\n",
    "        continue\n",
    "\n",
    "    # celln\n",
    "    celln += 1\n",
    "\n",
    "    # configure plots\n",
    "    close_local = ppm.close_plot(celln,ifig,ptrack)\n",
    "    if close_local[0]:\n",
    "        plt.close(fig); ifig += 1; fig = plt.figure(ifig,figsize=(mollSize*mollRatio,mollSize),dpi=300)\n",
    "        ppm.add_plot(celln,ifig,ptrack)\n",
    "    else:\n",
    "        ifig += 1; fig = plt.figure(ifig,figsize=(mollSize*mollRatio,mollSize),dpi=300)\n",
    "        ppm.add_plot(celln,ifig,ptrack)\n",
    "\n",
    "    ax = plt.axes([0.01, 0.01, 0.98, 0.88], projection='mollweide')\n",
    "    \n",
    "    # remove points that are part of the upper or lower boundaries of my search for the boundary\n",
    "    remove = np.logical_not(((utr_bound[runstr] <= rbot_ut) & (utr_bound[runstr] >= rtop_ut)))\n",
    "\n",
    "    # 3 sigma bounds\n",
    "    utr_bound_mean = utr_bound[runstr][remove].mean()\n",
    "    uval = utr_bound_mean + 3 * np.std(utr_bound[runstr][remove])\n",
    "    lval = utr_bound_mean - 3 * np.std(utr_bound[runstr][remove])\n",
    "    \n",
    "    # plot\n",
    "    ax.scatter(phi_ut_boundary[runstr][remove], theta_ut_boundary[runstr][remove], s=(72./fig.dpi)**2, \n",
    "                       marker=',',c=utr_bound[runstr][remove],cmap='PuOr',rasterized=True,\n",
    "                vmin=lval, vmax=uval)\n",
    "\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.grid(color='k', linewidth=gridlines)\n",
    "\n",
    "    # create a colorbar for the axs1 tripcolor, take part of the axes\n",
    "    cax = fig.add_axes([0.01, 0.03, 0.98, 0.03])\n",
    "    cbar1 = fig.colorbar(ax.collections[0], cax=cax, orientation='horizontal',format='%.1f',\n",
    "                         label=r'Convective Boundary / Mm')\n",
    "\n",
    "    # savefig\n",
    "    if save:\n",
    "        fig.savefig(savefig[runstr],bbox_inches = \"tight\",dpi=300)\n",
    "    if not render:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fractional Area and Mass Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if i want to look at one particular run and/or radii\n",
    "runs_plot = ['n16']\n",
    "\n",
    "# plot stuff\n",
    "savefig = collections.OrderedDict(zip(run.keys(), ['N15-fractional.pdf', 'N16-fractional.png',\n",
    "                                                  'N17-fractional.pdf']))\n",
    "\n",
    "render = False\n",
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 89\n",
    "\n",
    "# loop through every run\n",
    "for runstr, myrun in run.items():\n",
    "    \n",
    "    # are we working with every run?\n",
    "    if runstr not in runs_plot:\n",
    "        continue\n",
    "\n",
    "    # celln\n",
    "    celln += 1\n",
    "\n",
    "    # configure plots\n",
    "    close_local = ppm.close_plot(celln,ifig,ptrack)\n",
    "    if close_local[0]:\n",
    "        plt.close(fig); ifig += 1; fig = plt.figure(ifig,figsize=(mollSize*mollRatio,mollSize),dpi=300)\n",
    "        ppm.add_plot(celln,ifig,ptrack)\n",
    "    else:\n",
    "        ifig += 1; fig = plt.figure(ifig,figsize=(mollSize*mollRatio,mollSize),dpi=300)\n",
    "        ppm.add_plot(celln,ifig,ptrack)\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    # plot fractional Area\n",
    "    ax.plot(radii_fluxFA[runstr], FA_up[runstr], color=cb(0)[2], ls='-', label='Fractional Area')\n",
    "    ax.plot(radii_fluxFA[runstr], 1 - FA_up[runstr], color=cb(0)[2], ls='--')\n",
    "    \n",
    "    # plot fractional mass flux\n",
    "    ax.plot(radii_fluxFA[runstr], flux_up[runstr], color=cb(1)[2], ls='-', label='Fractional Mass Flux')\n",
    "    ax.plot(radii_fluxFA[runstr], 1 - flux_up[runstr], color=cb(1)[2], ls='--')\n",
    "    \n",
    "    # set xlim, ylim\n",
    "    ax.set_xlim([radii_fluxFA[runstr].min(), radii_fluxFA[runstr].max()])\n",
    "    ax.set_xlabel('r / Mm')\n",
    "#     ax.set_ylabel('Fractional')\n",
    "    ax.legend(frameon=False)\n",
    "    \n",
    "    # savefig\n",
    "    if save:\n",
    "        fig.savefig(savefig[runstr],bbox_inches = \"tight\",dpi=300)\n",
    "    if not render:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ur Spectrum Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the radial velocity spectrum for each run? Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary that are run dependent\n",
    "radii = collections.OrderedDict((run, []) for run in runs)\n",
    "power_ur_l_r_lmax = collections.OrderedDict((run, []) for run in runs)\n",
    "radii_l = collections.OrderedDict((run, []) for run in runs)\n",
    "power_ur_l_r = collections.OrderedDict((run, []) for run in runs)\n",
    "l_r = collections.OrderedDict((run, []) for run in runs)\n",
    "offset = collections.OrderedDict((run, []) for run in runs)\n",
    "\n",
    "# constants\n",
    "lmax = 50\n",
    "min_r = m2r(run['n16'].mbot, run['n16'], run['n16'].dump0)\n",
    "max_r = m2r(run['n16'].mtop, run['n16'], run['n16'].dump0)\n",
    "radii_low = 14.5\n",
    "radii_high = 23\n",
    "myl_radii = [8.5, radii_low, radii_high]\n",
    "offset_r = [5e-2, 5e-1, 1e3]\n",
    "\n",
    "# loop through the different runs\n",
    "for runstr, myrun in run.items():\n",
    "    deex = myrun.rprof.get('deex',0)\n",
    "    radii[runstr] = np.linspace(min_r,max_r, int((max_r - min_r)/deex))\n",
    "    power_ur_l_r_lmax[runstr] = np.zeros((lmax, len(radii[runstr])))\n",
    "    radii_l[runstr] = myl_radii.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the different runs\n",
    "for runstr, myrun in run.items():\n",
    "    \n",
    "    # grab the radial velocity on the grid\n",
    "    ur = myrun.moms.get_spherical_components('ux','uy','uz',fname=myrun.dump0)[0]\n",
    "    \n",
    "    # for the spectrogram\n",
    "    # for each radii, get power spectrum\n",
    "    for counter, radius in enumerate(radii[runstr]):\n",
    "        \n",
    "        # what is lmax at this radius?\n",
    "        lmax_r, N, npoints = myrun.moms.sphericalHarmonics_lmax(radius)\n",
    "        \n",
    "        # Calculate spherical harmonics up to lmax\n",
    "        ur_interp = myrun.moms.sphericalHarmonics_format(ur, radius, lmax=lmax)\n",
    "        \n",
    "        # get coefficients and power, drop l=0!\n",
    "        coeffs = pyshtools.expand.SHExpandDH(ur_interp, sampling=2)\n",
    "        power_ur_l_r_lmax[runstr][:, counter] = pyshtools.spectralanalysis.spectrum(coeffs,\n",
    "                                                                                     unit='per_l')[1:]\n",
    "\n",
    "        # set to zero if lmax_r < lmax\n",
    "        if lmax_r < lmax:\n",
    "            power_ur_l_r_lmax[runstr][int((lmax_r-1)):, counter] = 0\n",
    "            \n",
    "    # for the particular l radii\n",
    "    for counter, radius in enumerate(radii_l[runstr]):\n",
    "        \n",
    "        # what is lmax at this radius?\n",
    "        lmax_r, N, npoints = myrun.moms.sphericalHarmonics_lmax(radius)\n",
    "        \n",
    "        # setup the correct power array\n",
    "        power_array = np.zeros(lmax_r)\n",
    "        \n",
    "        # Calculate spherical harmonics up to lmax_r\n",
    "        ur_interp = myrun.moms.sphericalHarmonics_format(ur, radius, lmax=lmax_r)\n",
    "        \n",
    "        # get coefficients and power, drop l=0!\n",
    "        coeffs = pyshtools.expand.SHExpandDH(ur_interp, sampling=2)\n",
    "        power_array = pyshtools.spectralanalysis.spectrum(coeffs, unit='per_l')[1:]\n",
    "        power_ur_l_r[runstr].append(power_array)\n",
    "        \n",
    "        # create the l array\n",
    "        l_r[runstr].append(np.arange(1,lmax_r+1))\n",
    "        \n",
    "        # arbitrary offset\n",
    "        offset[runstr].append(offset_r[counter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ur Spectrogram Fig 5 & 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot dependent dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if i want to look at one particular run\n",
    "runs_plot = ['n15', 'n16']\n",
    "\n",
    "# plot stuff\n",
    "savefig = collections.OrderedDict(zip(run.keys(), ['N15-vrspectra.pdf', 'N16-vrspectra.pdf',\n",
    "                                                  'N17-vrspectra.pdf']))\n",
    "render = True\n",
    "save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# celln\n",
    "celln = 14\n",
    "\n",
    "# loop through the different runs\n",
    "for runstr, myrun in run.items():\n",
    "    \n",
    "    if runstr not in runs_plot:\n",
    "        continue\n",
    "\n",
    "    celln += 1\n",
    "    \n",
    "    # configure plots\n",
    "    close_local = ppm.close_plot(celln,ifig,ptrack)\n",
    "    if close_local[0]:\n",
    "        plt.close(fig); ifig += 1; fig = plt.figure(ifig,figsize=(horizSize*horizRatio,horizSize),dpi=300)\n",
    "        ppm.add_plot(celln,ifig,ptrack)\n",
    "    else:\n",
    "        ifig += 1; fig = plt.figure(ifig,figsize=(horizSize*horizRatio,horizSize),dpi=300)\n",
    "        ppm.add_plot(celln,ifig,ptrack)\n",
    "        \n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    # I need to normalize by the logarithm\n",
    "    scaled_power = power_ur_l_r_lmax[runstr] / np.max(power_ur_l_r_lmax[runstr],axis=0)[np.newaxis, :]\n",
    "    vmax = 1.0\n",
    "    vmin = 1e-2\n",
    "    lognorm = colors.LogNorm(vmin=vmin, vmax=vmax, clip=True)\n",
    "\n",
    "    # imshow\n",
    "    ax.imshow(scaled_power,interpolation='none',origin='lower',norm=lognorm,aspect='auto',\n",
    "             extent=(radii[runstr][0]-0.5*np.diff(radii[runstr])[0],\n",
    "                     radii[runstr][-1] + 0.5*np.diff(radii[runstr])[0],0.5,0.5+lmax),\n",
    "             rasterized=True)\n",
    "\n",
    "    # create a colorbar for the axs1 tripcolor, use a new axes for it\n",
    "    cbar1 = fig.colorbar(ax.images[0], ax=ax, orientation='vertical', \n",
    "                 label=r'S$_{cc}(\\ell, r)$ / Max(S$_{cc}(r)$)',aspect=25)\n",
    "\n",
    "#     ax.axes.set_position([0.01, 0.01, 0.98, 0.78])\n",
    "    # plot details\n",
    "    ax.set_xlabel('r / Mm')\n",
    "    ax.set_ylabel(r'$\\ell$')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # savefig\n",
    "    if save:\n",
    "        fig.savefig(savefig[runstr],bbox_inches = \"tight\",dpi=300)\n",
    "    if not render:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\ell$ Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot dependent dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot stuff\n",
    "savefig = 'lspectrum.pdf'\n",
    "render = True\n",
    "save = True\n",
    "thickline = 1.5\n",
    "thinline = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# celln\n",
    "celln = 16\n",
    "        \n",
    "# configure plots\n",
    "close_local = ppm.close_plot(celln,ifig,ptrack)\n",
    "if close_local[0]:\n",
    "    plt.close(fig); ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "    ppm.add_plot(celln,ifig,ptrack)\n",
    "else:\n",
    "    ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "    ppm.add_plot(celln,ifig,ptrack)\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "cbc = 0\n",
    "\n",
    "# loop over length of the lists\n",
    "for i in range(len(power_ur_l_r['n15'])):\n",
    "    ax.plot(l_r['n15'][i],power_ur_l_r['n15'][i] / power_ur_l_r['n15'][2][0] * offset['n15'][i],ls=cb(cbc)[0],color=cb(cbc)[2],\n",
    "           linewidth=thinline)\n",
    "    ax.plot(l_r['n16'][i],power_ur_l_r['n16'][i] / power_ur_l_r['n15'][2][0] * offset['n16'][i],ls=cb(cbc)[0],color=cb(cbc)[2],\n",
    "           linewidth=thickline,label=r'r = {:0.1f}Mm'.format(myl_radii[i]))\n",
    "    cbc += 1\n",
    "   \n",
    "# plot details\n",
    "ax.set_xlabel(r'$\\ell$')\n",
    "ax.set_ylabel(r'Scaled Power')\n",
    "ax.set_xlim([1,500])\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.legend(frameon=False, loc='lower center')\n",
    "\n",
    "# savefig\n",
    "fig.tight_layout()\n",
    "if save:\n",
    "    fig.savefig(savefig,bbox_inches = \"tight\",dpi=300)\n",
    "if not render:\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainment Rate Fig 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is the entrainment rate evolving as a function of time for the two models during the advection post-processing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary that are run dependent\n",
    "var_value = collections.OrderedDict((run, []) for run in runs)\n",
    "ut_scaleheight_r = collections.OrderedDict((run, []) for run in runs)\n",
    "offset = collections.OrderedDict((run, []) for run in runs)\n",
    "dumpStart = collections.OrderedDict((run, []) for run in runs)\n",
    "dumpEnd = collections.OrderedDict((run, []) for run in runs)\n",
    "burn_func = collections.OrderedDict((run, []) for run in runs)\n",
    "\n",
    "# used for Paper derived quantities\n",
    "mdot_fit = collections.OrderedDict((run, []) for run in runs)\n",
    "mXcldir = collections.OrderedDict((run, []) for run in runs)\n",
    "mXcldb = collections.OrderedDict((run, []) for run in runs)\n",
    "entr_time = collections.OrderedDict((run, []) for run in runs)\n",
    "\n",
    "# constants\n",
    "r_min = 9.\n",
    "r_max = 28.\n",
    "\n",
    "# N15 linear regime\n",
    "index = np.argmin(abs(run['n15'].times - 300*60))\n",
    "\n",
    "# loop through the different runs\n",
    "for runstr, myrun in run.items():\n",
    "    \n",
    "    # range of dumps to calculate entrainment\n",
    "    dumpStart[runstr] = myrun.simDump0\n",
    "    dumpEnd[runstr] = myrun.dumpMax\n",
    "        \n",
    "    dumps = list(range(dumpStart[runstr], dumpEnd[runstr]))\n",
    "    var_value[runstr] = np.zeros(len(dumps))\n",
    "    ut_scaleheight_r[runstr] = np.zeros(len(dumps))\n",
    "    offset[runstr] = np.zeros(len(dumps))\n",
    "    \n",
    "    # need every dump to get var_value and the tangential velocity scale height\n",
    "    # I will remove an offset from this boundary for integration limit\n",
    "    if runstr == 'n17':\n",
    "        offset[runstr][:] = 5.0\n",
    "    else:\n",
    "        offset[runstr][:] = 0.5\n",
    "        \n",
    "    for counter,dump in enumerate(dumps):\n",
    "        var_value[runstr][counter] = float(m2r(myrun.mtop, myrun, dump)) - offset[runstr][counter]\n",
    "    \n",
    "    # rprof burn func\n",
    "    burn_func[runstr] = myrun.rprof.compute_rhodot_C12pg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot dependent dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if i want to look at one particular run and/or radii\n",
    "runs_plot = ['n15','n16','n17']\n",
    "\n",
    "# plot stuff\n",
    "savefig = collections.OrderedDict(zip(run.keys(), ['N15-entrainment.pdf', 'N16-entrainment.pdf',\n",
    "                                                  'N17-entrainment.pdf']))\n",
    "fit_interval = collections.OrderedDict(zip(run.keys(), \n",
    "                [[run['n15'].simTime0, run['n15'].times[np.argmin(abs(run['n15'].times - 300*60))]], None,\n",
    "                [run['n17'].simTime0, run['n17'].times[np.argmin(abs(run['n17'].times - 300*60))]]]))\n",
    "render = True\n",
    "save = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixing Timescales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we are burning material, we need to include the burn function (rhodot) and the Tcorr\n",
    "burn_args = {'T9corr_params':{'kind':1, 'params':{'a':0.46, 'b':0.77}}}\n",
    "celln = 17\n",
    "\n",
    "# loop through the different runs\n",
    "for runstr, myrun in run.items():\n",
    "\n",
    "    # configure plots\n",
    "    close_local = ppm.close_plot(celln,ifig,ptrack)\n",
    "    if close_local[0]:\n",
    "        plt.close(fig); ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "        ppm.add_plot(celln,ifig,ptrack)\n",
    "    else:\n",
    "        ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "        ppm.add_plot(celln,ifig,ptrack)\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "    cbc = 0\n",
    "    \n",
    "    # run the method\n",
    "    dumps = list(range(dumpStart[runstr], dumpEnd[runstr]))\n",
    "    \n",
    "\n",
    "    time, mir, mb = myrun.rprof.entr_rate(dumps, r_min, r_max, var='R', criterion='value',\n",
    "                                var_value=var_value[runstr], burn_func=burn_func[runstr], \n",
    "                                burn_args=burn_args, show_plots=False, return_time_series=True, \n",
    "                                fit_interval=fit_interval[runstr])\n",
    "\n",
    "    \n",
    "    # save these in dictionary for later analysis\n",
    "    mXcldir[runstr] = mir\n",
    "    mXcldb[runstr] = mb\n",
    "    entr_time[runstr]  = time\n",
    "    \n",
    "    # for later analysis, save n16 entrainment rate\n",
    "    if runstr == 'n16':\n",
    "        n16_mentrained = (mir + mb)\n",
    "    \n",
    "    # compute the entrained material\n",
    "    mentr = mir + mb\n",
    "    \n",
    "    # compute the linear fit\n",
    "    if fit_interval[runstr] is not None:\n",
    "        fit_idx0 = np.argmin(np.abs(time - fit_interval[runstr][0]))\n",
    "        fit_idx1 = np.argmin(np.abs(time - fit_interval[runstr][1])) + 1\n",
    "        fit_range = range(fit_idx0, fit_idx1)\n",
    "    else:\n",
    "        fit_range = range(0,len(time))\n",
    "        \n",
    "    mtot_fc = np.polyfit(time[fit_range], mentr[fit_range], 1)\n",
    "    mtot_fit = mtot_fc[0]*time[fit_range] + mtot_fc[1]\n",
    "    mdot = mtot_fc[0]\n",
    "        \n",
    "    # save the slope for later analysis\n",
    "    mdot_fit[runstr] = mdot\n",
    "    \n",
    "    # linear fit\n",
    "    mdot_str = '{:e}'.format(mdot)\n",
    "    parts = mdot_str.split('e')\n",
    "    mantissa = float(parts[0])\n",
    "    exponent = int(parts[1])\n",
    "    lbl = (r'$\\dot{{\\mathrm{{M}}}}_\\mathrm{{e}} = {:.2f} '\n",
    "           r'\\times 10^{{{:d}}}$ M$_\\odot$ s$^{{-1}}$').\\\n",
    "           format(mantissa, exponent)\n",
    "\n",
    "    ax.plot(time[fit_range]/60., mtot_fc[0]*time[fit_range] + mtot_fc[1], color=cb(4)[2], \n",
    "            ls='-', label=lbl, zorder=100)\n",
    "    if len(fit_range) != len(time):\n",
    "        new_range = range(len(fit_range),len(time))\n",
    "        ax.plot(time[new_range]/60., mtot_fc[0]*time[new_range] + mtot_fc[1], color=cb(4)[2], \n",
    "            ls=':', zorder=100)\n",
    "\n",
    "    ax.plot(time/60., mir, ':', color=cb(3)[2], label='present')\n",
    "    ax.plot(time/60., mb, '--', color=cb(6)[2], label='burnt')\n",
    "    ax.plot(time/60., mentr, color=cb(5)[2], label='total')\n",
    "\n",
    "    # plot details\n",
    "    ax.set_xlabel('t / min')\n",
    "    ax.set_ylabel(r'M$_{\\mathrm{e}}$ / M$_{\\odot}$')\n",
    "    myylim = [0, ax.get_ylim()[-1]]\n",
    "    ax.set_ylim(myylim)\n",
    "    ax.set_xlim([0,ax.get_xlim()[-1]])\n",
    "    if runstr == 'n17':\n",
    "        ax.vlines(myrun.times[1089]/60., *myylim, color='k', linestyle='-', linewidth=0.8)\n",
    "    ax.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    ax.legend(loc='upper left',frameon=False)\n",
    "    \n",
    "    # savefig\n",
    "    if save:\n",
    "        fig.savefig(savefig[runstr],bbox_inches = \"tight\",dpi=300)\n",
    "    if not render:\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the radial velocity timescale compare to the horizontal timescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary that are run dependent\n",
    "dt_radial = collections.OrderedDict((run, []) for run in runs)\n",
    "dt_horizontal = collections.OrderedDict((run, []) for run in runs)\n",
    "r_shell = collections.OrderedDict((run, []) for run in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the different runs\n",
    "for runstr, myrun in run.items():\n",
    "\n",
    "    # hydro is my hcore object\n",
    "    hydro = myrun\n",
    "\n",
    "    # get the \"r_onShell\" quantity and other vars\n",
    "    deex = hydro.rprof.get('deex', 0)\n",
    "    rconv_bot = m2r(hydro.mbot, hydro, hydro.dump0)\n",
    "    rconv_top = m2r(hydro.mtop, hydro, hydro.dump0)\n",
    "    r_onShell = np.linspace(rconv_bot, rconv_top, int((rconv_top - rconv_bot)/deex))\n",
    "    power_func = [gamma_weightedPower]\n",
    "    power_func_kwargs = [{}]\n",
    "    my_lmax = 500\n",
    "\n",
    "    gamma, dtr, dth = shellDerive(myrun.dump0, r_onShell)\n",
    "    \n",
    "    # set to the dictionaries\n",
    "    dt_radial[runstr] = dtr\n",
    "    dt_horizontal[runstr] = dth\n",
    "    r_shell[runstr] = r_onShell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot dependent dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if i want to look at one particular run and/or radii\n",
    "runs_plot = ['n16']\n",
    "\n",
    "# plot stuff\n",
    "savefig = collections.OrderedDict(zip(run.keys(), ['N15-timescales.pdf', 'N16-timescales.pdf',\n",
    "                                                  'N17-timescales.pdf']))\n",
    "render = True\n",
    "save = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 23\n",
    "\n",
    "# loop through every run\n",
    "for runstr, myrun in run.items():\n",
    "    \n",
    "    # are we working with every run?\n",
    "    if runstr not in runs_plot:\n",
    "        continue\n",
    "\n",
    "    # celln\n",
    "    celln += 1\n",
    "\n",
    "    # configure plots\n",
    "    close_local = ppm.close_plot(celln,ifig,ptrack)\n",
    "    if close_local[0]:\n",
    "        plt.close(fig); ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "        ppm.add_plot(celln,ifig,ptrack)\n",
    "    else:\n",
    "        ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "        ppm.add_plot(celln,ifig,ptrack)\n",
    "    \n",
    "    ax = fig.add_subplot(111)\n",
    "    cbc = 0\n",
    "    \n",
    "    # add the dmhdt\n",
    "    ax.plot(r_shell[runstr][1:],dt_radial[runstr].flatten(),ls=cb(cbc)[0],color=cb(cbc+8)[2],\n",
    "            label=r'$\\delta t_{\\mathrm{r}}$')\n",
    "    cbc += 1\n",
    "    \n",
    "    ax.plot(r_shell[runstr][1:],dt_horizontal[runstr].flatten(),ls=cb(0)[0],color=cb(cbc+14)[2],\n",
    "            label=r'$\\delta t_{\\mathrm{h}}$')\n",
    "    \n",
    "    # plot details\n",
    "    ax.set_xlabel('r / Mm')\n",
    "    ax.set_ylabel(r'Timescale / s')\n",
    "    ax.set_xlim([r_shell[runstr][0], r_shell[runstr][-1]])\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend(frameon=False, loc='center')\n",
    " \n",
    "    # savefig\n",
    "    fig.tight_layout()\n",
    "    if save:\n",
    "        fig.savefig(savefig[runstr],bbox_inches = \"tight\",dpi=300)\n",
    "    if not render:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Values in Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will print out all of the relevant quantities that the paper cites. Some are calculated throughout the notebook while others are directly calculated here. Make sure you run the whole notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heating region in the convection zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heating region constants\n",
    "radbase = 7.282\n",
    "dlayerbot = 2.0\n",
    "\n",
    "rminbase = radbase + .5 * dlayerbot\n",
    "rmaxbase = radbase + 1.5 * dlayerbot\n",
    "\n",
    "print('The top heating boundary is at {:.2f}Mm and the bottom heating boundary is at {:.2f}Mm'\n",
    "     .format(rminbase, rmaxbase))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transient State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does the transient state last for approximately in each run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot vrms as a function of time\n",
    "celln = 30\n",
    "render = True\n",
    "\n",
    "# celln\n",
    "celln += 1\n",
    "\n",
    "# configure plots\n",
    "close_local = ppm.close_plot(celln,ifig,ptrack)\n",
    "if close_local[0]:\n",
    "    plt.close(fig); ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "    ppm.add_plot(celln,ifig,ptrack)\n",
    "else:\n",
    "    ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "    ppm.add_plot(celln,ifig,ptrack)\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "cbc = 0\n",
    "\n",
    "# loop through every run\n",
    "for runstr, myrun in run.items():\n",
    "    \n",
    "    Urmax = np.zeros(len(myrun.dumps))\n",
    "    \n",
    "    # loop through every dump, get max |Ur|\n",
    "    for i,dump in enumerate(myrun.dumps):\n",
    "        U = myrun.rprof.get('|U|',fname=dump)\n",
    "        Ut = myrun.rprof.get('|Ut|',fname=dump)\n",
    "        Urmax[i] = np.sqrt(U**2 - Ut**2).max()\n",
    "        \n",
    "    ax.plot(myrun.times / 60., Urmax, ls=cb(cbc)[0], color=cb(cbc)[2],label=runstr.capitalize())\n",
    "    cbc += 1\n",
    "    \n",
    "ax.set_xlim([0,100])\n",
    "ax.set_ylabel(r'Ur / Mm s$^{-1}$')\n",
    "ax.set_xlabel('t / min')\n",
    "ax.legend()\n",
    "\n",
    "if not render:\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roughly 30 minutes into the simulation all transients are gone, what dump?\n",
    "transient = np.argmin(abs(run['n16'].times - 60*30))\n",
    "print('The dump that the transients end in ALL sims is {:d}'.format(transient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convective Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the convective turnover time as a function of time for each simulation?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries that are run dependent\n",
    "tau_conv = collections.OrderedDict((run, []) for run in runs)\n",
    "ur_avg = collections.OrderedDict((run, []) for run in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the convective turnover time, based on SC boundary, for all times and all runs\n",
    "for runstr, myrun in run.items():\n",
    "    \n",
    "    tau_conv[runstr] = np.zeros(len(myrun.dumps[myrun.simDump0:]))\n",
    "    ur_avg[runstr] = np.zeros(len(myrun.dumps[myrun.simDump0:]))\n",
    "    \n",
    "    # for every dump that we post-process\n",
    "    for i,dump in enumerate(myrun.dumps[myrun.simDump0:]):\n",
    "        \n",
    "        # schwarz\n",
    "        rtop = m2r(myrun.mtop, myrun, dump)\n",
    "        rbot = m2r(myrun.mbot, myrun, dump)\n",
    "        \n",
    "        # velocities and tau_conv\n",
    "        r = myrun.rprof.get('R',fname=dump,resolution='l')\n",
    "        ur = np.sqrt(myrun.rprof.get('|U|',fname=dump)**2 - myrun.rprof.get('|Ut|',fname=dump)**2)\n",
    "        \n",
    "        rtopi = np.argmin(abs(r - rtop))\n",
    "        rboti = np.argmin(abs(r - rbot))\n",
    "        \n",
    "        ur_avg[runstr][i] = (ur[rtopi:rboti+1].mean())\n",
    "        tau_conv[runstr][i] = ((rtop - rbot) / ur_avg[runstr][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot tau_conv as a function of time\n",
    "celln = 31\n",
    "render = True\n",
    "\n",
    "# celln\n",
    "celln += 1\n",
    "\n",
    "# configure plots\n",
    "close_local = ppm.close_plot(celln,ifig,ptrack)\n",
    "if close_local[0]:\n",
    "    plt.close(fig); ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "    ppm.add_plot(celln,ifig,ptrack)\n",
    "else:\n",
    "    ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "    ppm.add_plot(celln,ifig,ptrack)\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "cbc = 0\n",
    "\n",
    "# loop through every run\n",
    "for runstr, myrun in run.items():\n",
    "        \n",
    "    ax.plot(myrun.times[myrun.simDump0:] / 60., tau_conv[runstr] / 60., ls=cb(cbc)[0], \n",
    "            color=cb(cbc)[2],label=runstr.capitalize())\n",
    "    cbc += 1\n",
    "    \n",
    "ax.set_xlim([100,1700])\n",
    "ax.set_ylabel(r'$\\tau_{\\mathrm{conv}}$ / min')\n",
    "ax.set_xlabel('t / min')\n",
    "ax.legend()\n",
    "\n",
    "if not render:\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through every run\n",
    "for runstr, myrun in run.items():\n",
    "\n",
    "    # the average convective turnover time during quasistatic period\n",
    "    quasistatic = np.argmin(abs(myrun.times - 300))\n",
    "    avg_conv = tau_conv[runstr][0:(quasistatic-myrun.simDump0)].mean()\n",
    "    \n",
    "    print('{:s} average convective turnover time the post-processing simulation is {:.2f} min'\n",
    "         .format(runstr.capitalize(),avg_conv / 60.))\n",
    "    \n",
    "    # How long is 100 dumps?\n",
    "    print('A single dump has an interval of roughly {:.2f} s'.format(np.diff(myrun.times).mean()))\n",
    "    print('The 100 dump repeat at the start is roughly {:.2f} min or {:.1f} convective turnovers for N16'\n",
    "         .format(100*np.diff(myrun.times).mean()/60., 100*np.diff(myrun.times).mean()/avg_conv))\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How are the statistics of the upper boundary determined by v_perp at dump0/time0?**\n",
    "\n",
    "**What are the convective boundaries for both determinations at dump0/time0?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through every run\n",
    "for runstr, myrun in run.items():\n",
    "    \n",
    "    # grab schwarz boundary\n",
    "    rtop = m2r(myrun.mtop, myrun, myrun.dump0)\n",
    "    print('{:s} schwarz boundary is {:0.2f}Mm, v_perp boundary is {:0.2f}Mm with 1sigma {:0.2f}Mm'\n",
    "          .format(runstr.capitalize(), rtop, float(utr_bound[runstr].mean()), \n",
    "                  1*float(utr_bound[runstr].std())))\n",
    "    \n",
    "    # get the pressure scale height there\n",
    "    Hp = myrun.rprof.compute_Hp(myrun.dump0)\n",
    "    r = myrun.rprof.get('R',fname=myrun.dump0,resolution='l')\n",
    "    Hp_bound = Hp[np.argmin(abs(float(utr_bound[runstr].mean()) - r))]\n",
    "    print('The pressure scale height at boundary is {:0.2f}Mm'.format(Hp_bound))\n",
    "    print('The grid resolution is {:0.2f}Mm'.format(myrun.moms.moms_gridresolution))    \n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrainment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the linear fit to the entrainment rates?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through every run\n",
    "for runstr, myrun in run.items():\n",
    "    print('{:s} mdot linear fit, is {:.2e} Msolar/s'.format(runstr.capitalize(), mdot_fit[runstr]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does the integrated entrainment of mass compare with the smallest cell in post-processing?**\n",
    "\n",
    "**How many post-processing cells are there?**\n",
    "\n",
    "**How many factors does the entrainment rate increase during a GOSH?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through every run\n",
    "for runstr, myrun in run.items():\n",
    "    \n",
    "    # read in shell file\n",
    "    data, header = readSCFile(myrun.initbase, 'shell', myrun.dump0)\n",
    "    min_mcell = np.min(np.abs(np.diff(data['m']))/2.)\n",
    "    \n",
    "    # total entrained material\n",
    "    tot_entrained = (mXcldir[runstr] + mXcldb[runstr])[-1]\n",
    "    \n",
    "    print('The smallest mass cell is {:.2e} while the total entrained material is {:.2e}'\n",
    "          .format(min_mcell * 1e27/Msun, tot_entrained))\n",
    "    print('There are {:d} cells in the post-processing'.format(len(data['m']-1)))\n",
    "    \n",
    "    # calculate the entrainment rate\n",
    "    myentr_rate =  ppm.cdiff(mXcldir[runstr] + mXcldb[runstr]) / ppm.cdiff(entr_time[runstr])\n",
    "    print('The maximum GOSH entrainment rate is a factor of {:.1f} times larger than the linear fit'\n",
    "         .format(np.max(myentr_rate)/mdot_fit[runstr]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
