{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to actually create pdf files of the figures set the variable `save = True` some way down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# %pylab ipympl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib as mpl\n",
    "import scipy.integrate\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "# spherical harmonics tools\n",
    "import pyshtools.expand \n",
    "import pyshtools.spectralanalysis\n",
    "\n",
    "# my modules\n",
    "# pwd = os. getcwd()\n",
    "# nugridpy_git = \"9414d08\" # make pre-processing files and marker options for multiple abu_profile plot\n",
    "# nugridpy_dir = '/user/scratch14_csa/dstephens/NuGridPy'\n",
    "# os.chdir(nugridpy_dir)\n",
    "# git_hash = os.popen('git rev-parse --short HEAD').read().rstrip()\n",
    "# if not git_hash == nugridpy_git: \n",
    "#     print(\"WARNING: NuGridPy should be on \"+nugridpy_git+\" but is on \"+git_hash)\n",
    "\n",
    "# nugridpy_dir='/user/scratch14_wendi3/fherwig/test-nugridse-feb2021/GitHub/NuGridPy'\n",
    "import nugridpy.ascii_table as table\n",
    "from nugridpy import nugridse as nuse\n",
    "import nugridpy.utils as utils\n",
    "import nugridpy.astronomy as ast\n",
    "\n",
    "from astropy import constants as const\n",
    "from astropy import units as u\n",
    "\n",
    "Msun = (const.M_sun.to(u.g)).value\n",
    "Rsun = (const.R_sun.to(u.cm)).value\n",
    "\n",
    "# pyppm_git = '582dd18'\n",
    "# pyppm_dir = '/user/scratch14_csa/dstephens/PyPPM/'\n",
    "# os.chdir(pyppm_dir)\n",
    "# git_hash = os.popen('git rev-parse --short HEAD').read().rstrip()\n",
    "# if not git_hash == pyppm_git: \n",
    "#     print(\"WARNING: PyPPM should be on \"+pyppm_git+\" but is on \"+git_hash)\n",
    "pyppm_dir = '/user/niagara_scratch_fherwig/repos/PyPPM/'\n",
    "sys.path.insert(0,pyppm_dir)  \n",
    "from ppmpy import ppm\n",
    "\n",
    "##########################################################################\n",
    "# os.chdir(pwd)\n",
    "cb = utils.linestylecb # colours\n",
    "\n",
    "# plot things\n",
    "ifig = 0\n",
    "ptrack = {}\n",
    "\n",
    "# figure sizes\n",
    "stdSize = 4.\n",
    "stdRatio = 4./3.\n",
    "\n",
    "# turn off matplotlib messages\n",
    "logging.getLogger(\"matplotlib\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to easily compare between the two models, a master dictionary is used\n",
    "run_dependent_quantities = ['moms', 'rprof', 'dump0', 'time0', 'dumpMax', 'dumps', 'times', 'initbase', \n",
    "                            'simDump0', 'simTime0', 'simDumpMax', 'mbot', 'mtop', 'DFVvr_c12pg', \n",
    "                            'Dvr_c12pg', 'up_c12pg', 'down_c12pg', 'DFVvr_fnet', 'Dvr_fnet', 'up_fnet',\n",
    "                            'down_fnet', 'nrepeatDump0', 'nsubt']\n",
    "runs = ['n16', 'n17']\n",
    "\n",
    "# to get \"run_dependent_quantities\", use a named tuple\n",
    "allruns = collections.namedtuple('allruns', run_dependent_quantities)\n",
    "\n",
    "# temporary fill values for anything past rprof\n",
    "tempfill = [40] * (len(run_dependent_quantities)-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the paper may change since the origin of this notebook, the figures and what they are conveying should not change significantly. The plots are done in sections like that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "collect all of the quantities for each named tuple and create the master dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N16\n",
    "moms_dir = '/data/ASDR/PPMstar/LowZRAWD/N16-LowZRAWD-1536-10x-burn-moms/myavsbq'\n",
    "rprof_dir = '/data/ASDR/PPMstar/LowZRAWD/N16-LowZRAWD-1536-10x-burn-moms/prfs/'\n",
    "\n",
    "var_list = ['xc','ux','uy','uz','|ut|','|ur|','|w|','P','rho','fv']\n",
    "n16 = allruns(ppm.MomsDataSet(moms_dir,400,2,var_list,rprofset=ppm.RprofSet(rprof_dir)),\n",
    "              ppm.RprofSet(rprof_dir),*tempfill)\n",
    "\n",
    "# N17\n",
    "moms_dir = '/data/ASDR/PPMstar/LowZRAWD/N17-LowZRAWD-1152-100x-burn-moms/myavsbq'\n",
    "rprof_dir = '/data/ASDR/PPMstar/LowZRAWD/N17-LowZRAWD-1152-100x-burn-moms/prfs/'\n",
    "\n",
    "var_list = ['xc','ux','uy','uz','|ut|','|ur|','|w|','P','rho','fv']\n",
    "n17 = allruns(ppm.MomsDataSet(moms_dir,400,2,var_list,rprofset=ppm.RprofSet(rprof_dir)),\n",
    "              ppm.RprofSet(rprof_dir),*tempfill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convenience functions used throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a mass coordinate to radius\n",
    "def m2r(masscoord, myrun, dump):\n",
    "    # stop printing, too much\n",
    "    devnull = open(os.devnull, 'w')\n",
    "    with RedirectStdStreams(stdout=devnull, stderr=devnull):\n",
    "        m = myrun.rprof.compute_m(dump)\n",
    "        r = myrun.rprof.get('R',fname=dump,resolution='l')\n",
    "    return ppm.interpolate(m,r,masscoord)\n",
    "\n",
    "def readSCFile(initbase, fileExt, dump):\n",
    "    \"\"\"\n",
    "    Read in a .shell or .central file at dump\n",
    "    Returns the data and header dictionaries\n",
    "    \"\"\"\n",
    "\n",
    "    # counters\n",
    "    headerLines = 0\n",
    "    dataLines = 0\n",
    "\n",
    "    # lists to hold results\n",
    "    data_keys =[]\n",
    "    header = {}\n",
    "\n",
    "    # open the file\n",
    "    openfile = initbase + '-{0:04d}.{1:s}'.format(dump, fileExt)\n",
    "\n",
    "    with open(openfile) as myfile:\n",
    "\n",
    "        # get all lines\n",
    "        lines = [line.rstrip() for line in myfile]\n",
    "\n",
    "        # run through the lines\n",
    "        for line in lines:\n",
    "\n",
    "            # grab the data keys\n",
    "            if line.startswith('#'):\n",
    "                data_keys.extend(line.split(' ')[1:])\n",
    "                headerLines += 1\n",
    "\n",
    "            # Grab the header data\n",
    "            elif line.find('=') != -1:\n",
    "\n",
    "                # split across = sign, remove whitespace\n",
    "                split = line.split('=')\n",
    "\n",
    "                # Now I need to know what type the header should be!\n",
    "                if split[1].strip().isdecimal():\n",
    "                    hval = int(split[1].strip())\n",
    "                elif split[1].strip().find('.') != -1:\n",
    "                    hval = float(split[1].strip())\n",
    "                else:\n",
    "                    hval = split[1].strip()\n",
    "\n",
    "                # put into dictionary\n",
    "                header[split[0].strip()] = hval\n",
    "                headerLines += 1\n",
    "\n",
    "            # we are now reading in data, this is after all header data\n",
    "            else:\n",
    "\n",
    "                # if we are at the first line, create arrays and dict\n",
    "                if dataLines == 0:\n",
    "                    data = collections.OrderedDict(zip(data_keys,\n",
    "                                    map(np.zeros, [len(lines) - headerLines] * len(data_keys))))\n",
    "\n",
    "                # split the line into its numbers\n",
    "                line = \" \".join(line.split())\n",
    "                split = line.split(' ')\n",
    "\n",
    "                for i, key in enumerate(data.keys()):\n",
    "                    data[key][dataLines] = float(split[i])\n",
    "\n",
    "                # update line number\n",
    "                dataLines += 1\n",
    "                \n",
    "    return data, header\n",
    "\n",
    "# use remove print to console at certain points then return\n",
    "class RedirectStdStreams(object):\n",
    "    def __init__(self, stdout=None, stderr=None):\n",
    "        self._stdout = stdout or sys.stdout\n",
    "        self._stderr = stderr or sys.stderr\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.old_stdout, self.old_stderr = sys.stdout, sys.stderr\n",
    "        self.old_stdout.flush(); self.old_stderr.flush()\n",
    "        sys.stdout, sys.stderr = self._stdout, self._stderr\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self._stdout.flush(); self._stderr.flush()\n",
    "        sys.stdout = self.old_stdout\n",
    "        sys.stderr = self.old_stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mppnp se file convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nsubt(initbase, simDump0, simDumpMax):\n",
    "    \n",
    "    # return an array with the nsubt timesteps taken at every dump within the simulation time\n",
    "    \n",
    "    # what dumps are we going to read in\n",
    "    dumps = list(range(simDump0, simDumpMax))\n",
    "    nsubt = np.zeros(len(dumps), dtype=np.int16)\n",
    "    \n",
    "    for i,dump in enumerate(dumps):\n",
    "\n",
    "        # read in file\n",
    "        data, headers = readSCFile(initbase,'shell', dump)\n",
    "        nsubt[i] = int(headers['subtimesteps'])\n",
    "        \n",
    "    return nsubt\n",
    "\n",
    "def removelists(se, get_quantity, cycle):\n",
    "    \n",
    "    # with all mppnp runs there is a possibility of getting a list of results. Take the last one\n",
    "    got_quantity = se.get(int(cycle), get_quantity)\n",
    "    \n",
    "    # I have ~250 zones in all, if its len is small, it is a list\n",
    "    if len(got_quantity) < 100:\n",
    "        got_quantity = got_quantity[-1]\n",
    "    \n",
    "    return got_quantity\n",
    "\n",
    "# get the correpsonding cycle from a ppmstar dump\n",
    "def dump2cycle(nrepeat, nsubt, dump, simDump0):\n",
    "    if dump == simDump0:\n",
    "        return int(nrepeat)\n",
    "    else:\n",
    "        return int(nrepeat + nsubt[0:(dump-simDump0)].sum())\n",
    "    \n",
    "# Transform a shell quantity to a central quantity\n",
    "def shell2central(shell_quantity):\n",
    "    return ((np.roll(shell_quantity, -1) + shell_quantity) / 2.)[0:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burning calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vc12pg(T9, rho):\n",
    "    \"\"\"\n",
    "    Reaction rate of C12(p, gamma)N13\n",
    "    \"\"\"\n",
    "\n",
    "    # a ton of coefficients\n",
    "    TP13 = T9**(1./3.)\n",
    "    TP23 = TP13*TP13\n",
    "    TP12 = np.sqrt(T9)\n",
    "    TP14 = np.sqrt(TP12)\n",
    "    TP32 = T9*TP12\n",
    "    TM13 = 1./TP13\n",
    "    TM23 = 1./TP23\n",
    "    TM32 = 1./TP32\n",
    "\n",
    "    T9inv = 1. / T9\n",
    "    thyng = 2.173913043478260869565 * T9\n",
    "    vc12pg = 20000000.*TM23 * np.exp(-13.692*TM13 - thyng*thyng)\n",
    "    vc12pg = vc12pg * (1. + T9*(9.89-T9*(59.8 - 266.*T9)))\n",
    "    thing2 = vc12pg + TM23 * 1.0e5 * np.exp(-4.913*T9inv) + \\\n",
    "                      TM32 * 4.24e5 * np.exp(-21.62*T9inv)\n",
    "\n",
    "    thing2[np.where(T9 < .0059)] = 0.\n",
    "    thing2[np.where(T9 > 0.75)] = 200.\n",
    "\n",
    "    # multiply the reaction rate by 1000 because density is 1000 g / cm^3\n",
    "    vc12pg = thing2 * rho * 1000.\n",
    "\n",
    "    return vc12pg\n",
    "\n",
    "def drhoH_dt(XH, XC12, rho, T9, dV):\n",
    "    \n",
    "    # constants\n",
    "    AH = 1.\n",
    "    AC12 = 12.\n",
    "\n",
    "    # rho is in PPMStar units\n",
    "    dm = rho * dV\n",
    "    \n",
    "    # get dYHdt and convert to drhodt\n",
    "    dYHdt = (XH / AH) * (XC12 / AC12) * vc12pg(T9, rho)\n",
    "    drhoHdt = dYHdt * AH * dm / dV\n",
    "    \n",
    "    return drhoHdt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run and other Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomicnoH = 1.\n",
    "atomicnoC12 = 12.\n",
    "atomicnocld = n16.rprof.get('atomicnocld',fname=0)\n",
    "atomicnoair = n16.rprof.get('atomicnoair',fname=0)\n",
    "fkcld = n16.rprof.get('fkcld',fname=0)\n",
    "fkair = n16.rprof.get('fkair',fname=0)\n",
    "cldmu = n16.rprof.get('cldmu',fname=0)\n",
    "airmu = n16.rprof.get('airmu',fname=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything should be done at a single dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based off of N16\n",
    "n16_dump0 = 650\n",
    "n16_time0 = n16.rprof.get('t',n16_dump0)\n",
    "\n",
    "# i will construct the time arrays, history is wrong!\n",
    "n17_dumps = np.array(n17.rprof.get_dump_list())\n",
    "n16_dumps = np.array(n16.rprof.get_dump_list())\n",
    "n17_times = np.zeros(len(n17_dumps))\n",
    "n16_times = np.zeros(len(n16_dumps))\n",
    "\n",
    "for i,dump in enumerate(n17_dumps):\n",
    "    n17_times[i] = n17.rprof.get('t',dump)\n",
    "    \n",
    "for i,dump in enumerate(n16_dumps):\n",
    "    n16_times[i] = n16.rprof.get('t',dump)\n",
    "    \n",
    "# now find what the appropriate times are\n",
    "dumpi = np.argmin(abs(n16_time0 - n17_times))\n",
    "n17_dump0 = n16_dumps[dumpi]\n",
    "n17_time0 = n17_times[dumpi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing that the runs have been done for longer, there are some forced dumpMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n16_dumpMax = n16_dumps[-1]\n",
    "n17_dumpMax = n17_dumps[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the dump0 and time0 for the python simulation runs for post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the initbase, i.e reading in the run files\n",
    "base = '/data/niagara_project/projects/3D1D-advection/N16_shell_files'\n",
    "n16_initbase = os.path.join(base, 'N16-standard-mppnp', 'N16-standard-mppnp')\n",
    "data, header = readSCFile(n16_initbase, 'shell', 100)\n",
    "\n",
    "# grab the dump quantities\n",
    "n16_simDump0 = header['runDump']\n",
    "n16_simTime0 = n16_times[n16_simDump0]\n",
    "n16_simDumpMax = len([afile for afile in os.listdir(os.path.dirname(n16_initbase)) \n",
    "                      if os.path.isfile(os.path.join(os.path.dirname(n16_initbase), afile))]) - 1 + n16_simDump0\n",
    "\n",
    "# get the mass coordinates of the boundary\n",
    "n16_mbot = data['m'][0]\n",
    "n16_mtop = data['m'][-1]\n",
    "\n",
    "# set the initbase, i.e reading in the run files\n",
    "base = '/data/niagara_project/projects/3D1D-advection/N17_shell_files'\n",
    "n17_initbase = os.path.join(base, 'N17-standard-mppnp', 'N17-standard-mppnp')\n",
    "data, header = readSCFile(n17_initbase, 'shell', 100)\n",
    "\n",
    "# grab the dump quantities\n",
    "n17_simDump0 = header['runDump']\n",
    "n17_simTime0 = n17_times[n17_simDump0]\n",
    "n17_simDumpMax = len([afile for afile in os.listdir(os.path.dirname(n17_initbase)) \n",
    "                      if os.path.isfile(os.path.join(os.path.dirname(n17_initbase), afile))]) - 1 + n17_simDump0\n",
    "\n",
    "# get the mass coordinates of the boundary\n",
    "n17_mbot = data['m'][0]\n",
    "n17_mtop = data['m'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have mppnp post-processing simulations (note this takes a while (>5min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop printing, too much\n",
    "devnull = open(os.devnull, 'w')\n",
    "with RedirectStdStreams(stdout=devnull, stderr=devnull):\n",
    "    \n",
    "    # N16 C12pg, 100 repeats at the start\n",
    "    n16_nsubt = get_nsubt(n16_initbase, n16_simDump0, n16_simDumpMax)\n",
    "    n16_nrepeatDump0 = 100 * n16_nsubt[0]\n",
    "    \n",
    "    base = '/data/niagara_project/projects/3D1D-advection/mppnp-paper-data'\n",
    "    n16_up_c12pg = nuse.se(os.path.join(base, 'H5_out_up_mp2'))\n",
    "    n16_down_c12pg = nuse.se(os.path.join(base, 'H5_out_down_mp2'))\n",
    "    \n",
    "    base = '/data/niagara_project/projects/3D1D-advection/mppnp-paper-data'\n",
    "    n16_DFVvr_c12pg = nuse.se(os.path.join(base, 'H5_out_mes_mp1'))\n",
    "\n",
    "    base = '/data/niagara_project/projects/3D1D-advection/mppnp-paper-data'\n",
    "    n16_Dvr_c12pg = nuse.se(os.path.join(base, 'H5_out_mes_mp9'))\n",
    "\n",
    "    # N16 fnet, 100 repeats at the start\n",
    "    base = '/data/niagara_project/projects/3D1D-advection/mppnp-paper-data'\n",
    "    n16_up_fnet = nuse.se(os.path.join(base, 'H5_out_up_mp6'))\n",
    "    n16_down_fnet = nuse.se(os.path.join(base, 'H5_out_down_mp6'))  \n",
    "\n",
    "    base = '/data/niagara_project/projects/3D1D-advection/mppnp-paper-data'\n",
    "    n16_DFVvr_fnet = nuse.se(os.path.join(base, 'H5_out_mes_mp5'))\n",
    "    \n",
    "    base = '/data/niagara_project/projects/3D1D-advection/mppnp-paper-data'\n",
    "    n16_Dvr_fnet = nuse.se(os.path.join(base, 'H5_out_mes_mp10'))\n",
    "    \n",
    "    # N17 C12pg, 100 repeats at the start\n",
    "    n17_nsubt = get_nsubt(n17_initbase, n17_simDump0, n17_simDumpMax)\n",
    "    n17_nrepeatDump0 = 100 * n17_nsubt[0]\n",
    "    \n",
    "    base = '/data/niagara_project/projects/3D1D-advection/mppnp-paper-data'\n",
    "    n17_up_c12pg = nuse.se(os.path.join(base, 'H5_out_up_mp4'))\n",
    "    n17_down_c12pg = nuse.se(os.path.join(base, 'H5_out_down_mp4'))\n",
    "\n",
    "    n17_DFVvr_c12pg = 0\n",
    "\n",
    "    base = '/data/niagara_project/projects/3D1D-advection/mppnp-paper-data'\n",
    "    n17_Dvr_c12pg = nuse.se(os.path.join(base, 'H5_out_mes_mp3'))\n",
    "\n",
    "    # N17 fnet, 100 repeats at the start\n",
    "    base = '/data/niagara_project/projects/3D1D-advection/mppnp-paper-data'\n",
    "    n17_up_fnet = nuse.se(os.path.join(base, 'H5_out_up_mp8'))\n",
    "    n17_down_fnet = nuse.se(os.path.join(base, 'H5_out_down_mp8'))\n",
    "    \n",
    "    n17_DFVvr_fnet = 0\n",
    "    \n",
    "    base = '/data/niagara_project/projects/3D1D-advection/mppnp-paper-data'\n",
    "    n17_Dvr_fnet = nuse.se(os.path.join(base, 'H5_out_mes_mp7'))\n",
    "    \n",
    "# re-enable print\n",
    "print('And we are back!')\n",
    "devnull.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factors to convert back to PPMStar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# radius\n",
    "fac_rad = (n16_up_c12pg.se.get('radius_unit') / Rsun)\n",
    "# density\n",
    "fac_den = (n16_up_c12pg.se.get('rho_unit'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n16 = n16._replace(dump0=n16_dump0, time0=n16_time0, dumpMax=n16_dumpMax, dumps=n16_dumps, times=n16_times, \n",
    "                  initbase=n16_initbase, simDump0=n16_simDump0, simTime0=n16_simTime0, \n",
    "                  simDumpMax=n16_simDumpMax, mbot=n16_mbot, mtop=n16_mtop, DFVvr_c12pg=n16_DFVvr_c12pg,\n",
    "                  Dvr_c12pg=n16_Dvr_c12pg, up_c12pg=n16_up_c12pg, down_c12pg=n16_down_c12pg,\n",
    "                  DFVvr_fnet=n16_DFVvr_fnet, Dvr_fnet=n16_Dvr_fnet, up_fnet=n16_up_fnet,\n",
    "                  down_fnet=n16_down_fnet, nrepeatDump0=n16_nrepeatDump0, nsubt=n16_nsubt)\n",
    "\n",
    "n17 = n17._replace(dump0=n17_dump0, time0=n17_time0, dumpMax=n17_dumpMax, dumps=n17_dumps, times=n17_times, \n",
    "                  initbase=n17_initbase, simDump0=n17_simDump0, simTime0=n17_simTime0, \n",
    "                  simDumpMax=n17_simDumpMax, mbot=n17_mbot, mtop=n17_mtop, DFVvr_c12pg=n17_DFVvr_c12pg,\n",
    "                  Dvr_c12pg=n17_Dvr_c12pg, up_c12pg=n17_up_c12pg, down_c12pg=n17_down_c12pg,\n",
    "                  DFVvr_fnet=n17_DFVvr_fnet, Dvr_fnet=n17_Dvr_fnet, up_fnet=n17_up_fnet,\n",
    "                  down_fnet=n17_down_fnet, nrepeatDump0=n17_nrepeatDump0, nsubt=n17_nsubt)\n",
    "\n",
    "# master dictionary\n",
    "run = collections.OrderedDict(zip(runs, [n16, n17]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Burning Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where is the H burning in the post-processing models and the hydro models. Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary that are run dependent\n",
    "r_PPM = collections.OrderedDict((run, []) for run in runs)\n",
    "r_mppnp = collections.OrderedDict((run, []) for run in runs)\n",
    "\n",
    "drhoHdt_PPM = collections.OrderedDict((run, []) for run in runs)\n",
    "drhoHdt_mppnp_up = collections.OrderedDict((run, []) for run in runs)\n",
    "drhoHdt_mppnp_down = collections.OrderedDict((run, []) for run in runs)\n",
    "drhoHdt_mppnp_ud_avg = collections.OrderedDict((run, []) for run in runs)\n",
    "drhoHdt_mppnp_Dvr = collections.OrderedDict((run, []) for run in runs)\n",
    "drhoHdt_mppnp_DFVvr = collections.OrderedDict((run, []) for run in runs)\n",
    "\n",
    "# for different plots at different times; THIS IS THE same as C12pg profiles!\n",
    "run_dump = collections.OrderedDict(zip(runs,[650, 1089]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run['n16'].times[1089] / 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature corrections are needed...\n",
    "T9corr_params = {'kind':1, 'params':{'a':0.46, 'b':0.77}}\n",
    "burn_args = {'T9corr_params':T9corr_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the different runs\n",
    "for runstr, myrun in run.items():\n",
    "    \n",
    "    # get dt over the time step\n",
    "    dt = np.diff(myrun.times)[run_dump[runstr]]\n",
    "                           \n",
    "    # get the dmXhdt from PPMStar\n",
    "    r_PPM[runstr] = myrun.rprof.get('R',fname=run_dump[runstr],resolution='l')                                         \n",
    "    dV = -4 * np.pi * r_PPM[runstr]**2 * ppm.cdiff(r_PPM[runstr])\n",
    "    \n",
    "    # try with the vc12pg equation I have\n",
    "    Tcorr = myrun.rprof.compute_T9corr(fname=run_dump[runstr], kind=T9corr_params['kind'],\n",
    "                                       params=T9corr_params['params'])\n",
    "    rho = myrun.rprof.get('Rho0',fname=run_dump[runstr],resolution='l') + myrun.rprof.get('Rho1',fname=run_dump[runstr],resolution='l')\n",
    "    Xcld = myrun.rprof.compute_Xcld(run_dump[runstr])\n",
    "    XH = Xcld * fkcld * atomicnoH / atomicnocld\n",
    "    XC12 = (1-Xcld) * fkair * atomicnoC12 / atomicnoair\n",
    "    drhoHdt_PPM[runstr] = drhoH_dt(XH, XC12, rho, Tcorr, -dV)\n",
    "    \n",
    "    # For mppnp use shell files for rho, T and r. Use se for mass fractions  \n",
    "    # I need to read in the structure for mppnp. It should be exactly the shell files\n",
    "    data, header = readSCFile(myrun.initbase, 'shell', run_dump[runstr])\n",
    "    rho_mppnp = shell2central(data['rho'])\n",
    "    T9_mppnp = data['T9'][0:-1]\n",
    "    r_mppnp[runstr] = shell2central(data['r'])\n",
    "    \n",
    "    dV_mppnp = 2. * np.pi * r_mppnp[runstr]**2 * ppm.cdiff(r_mppnp[runstr])\n",
    "\n",
    "    XH_up = removelists(myrun.up_c12pg, 'H-1', dump2cycle(myrun.nrepeatDump0, myrun.nsubt, run_dump[runstr], myrun.simDump0))\n",
    "    XH_down = removelists(myrun.down_c12pg, 'H-1', dump2cycle(myrun.nrepeatDump0, myrun.nsubt, run_dump[runstr], myrun.simDump0))\n",
    "    XH_Dvr = removelists(myrun.Dvr_c12pg, 'H-1', dump2cycle(myrun.nrepeatDump0, myrun.nsubt, run_dump[runstr], myrun.simDump0))\n",
    "    if runstr != 'n17':\n",
    "        XH_DFVvr = removelists(myrun.DFVvr_c12pg, 'H-1', dump2cycle(myrun.nrepeatDump0, myrun.nsubt, run_dump[runstr], myrun.simDump0))\n",
    "\n",
    "    XC12_up = removelists(myrun.up_c12pg, 'C-12', dump2cycle(myrun.nrepeatDump0, myrun.nsubt, run_dump[runstr], myrun.simDump0))\n",
    "    XC12_down = removelists(myrun.down_c12pg, 'C-12', dump2cycle(myrun.nrepeatDump0, myrun.nsubt, run_dump[runstr], myrun.simDump0))\n",
    "    XC12_Dvr = removelists(myrun.Dvr_c12pg, 'C-12', dump2cycle(myrun.nrepeatDump0, myrun.nsubt, run_dump[runstr], myrun.simDump0))\n",
    "    if runstr != 'n17':\n",
    "        XC12_DFVvr = removelists(myrun.DFVvr_c12pg, 'C-12', dump2cycle(myrun.nrepeatDump0, myrun.nsubt, run_dump[runstr], myrun.simDump0))\n",
    "    \n",
    "    drhoHdt_mppnp_up[runstr] = drhoH_dt(XH_up, XC12_up, rho_mppnp, T9_mppnp, dV_mppnp)\n",
    "    drhoHdt_mppnp_down[runstr] = drhoH_dt(XH_down, XC12_down, rho_mppnp, T9_mppnp, dV_mppnp)\n",
    "    drhoHdt_mppnp_ud_avg[runstr] = drhoH_dt((XH_down+XH_up)/2., (XC12_down +XC12_up)/2., rho_mppnp, T9_mppnp, 2*dV_mppnp)\n",
    "    drhoHdt_mppnp_Dvr[runstr] = drhoH_dt(XH_Dvr, XC12_Dvr, rho_mppnp, T9_mppnp, 2*dV_mppnp)\n",
    "    if runstr != 'n17':\n",
    "        drhoHdt_mppnp_DFVvr[runstr] = drhoH_dt(XH_DFVvr, XC12_DFVvr, rho_mppnp, T9_mppnp, 2*dV_mppnp)\n",
    "    else:\n",
    "        drhoHdt_mppnp_DFVvr[runstr] = 0.\n",
    "        \n",
    "    # convert to solar mass\n",
    "    solmass = 1.e27/Msun\n",
    "    drhoHdt_PPM[runstr] *= solmass\n",
    "    drhoHdt_mppnp_up[runstr] *= solmass\n",
    "    drhoHdt_mppnp_down[runstr] *= solmass\n",
    "    drhoHdt_mppnp_ud_avg[runstr] *= solmass\n",
    "    drhoHdt_mppnp_Dvr[runstr] *= solmass\n",
    "    drhoHdt_mppnp_DFVvr[runstr] *= solmass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot dependent dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if i want to look at one particular run and/or radii\n",
    "runs_plot = ['n16']\n",
    "\n",
    "# plot stuff\n",
    "savefig = collections.OrderedDict(zip(run.keys(), ['N16-drhoHdt.pdf', 'N17-drhoHdt.pdf']))\n",
    "render = True\n",
    "save = False\n",
    "\n",
    "# for any run, plot quantity dependencies\n",
    "ls = ['-', '--', '-', '-.', ':']\n",
    "color = [cb(1)[2], cb(2)[2], cb(3)[2], cb(4)[2], cb(8)[2]]\n",
    "marker = ['>', '<', None, 'o', 'x']\n",
    "markevery = [10, 10, 10, 10, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 21\n",
    "\n",
    "# loop through every run\n",
    "for runstr, myrun in run.items():\n",
    "    \n",
    "    # are we working with every run?\n",
    "    if runstr not in runs_plot:\n",
    "        continue\n",
    "\n",
    "    # celln\n",
    "    celln += 1\n",
    "\n",
    "    # configure plots\n",
    "    close_local = ppm.close_plot(celln,ifig,ptrack)\n",
    "    if close_local[0]:\n",
    "        plt.close(fig); ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "        ppm.add_plot(celln,ifig,ptrack)\n",
    "    else:\n",
    "        ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "        ppm.add_plot(celln,ifig,ptrack)\n",
    "    \n",
    "    ax = fig.add_subplot(111)\n",
    "    cbc = 0\n",
    "\n",
    "    ax.plot(r_PPM[runstr],drhoHdt_PPM[runstr],ls=cb(0)[0],color=cb(0)[2],label='PPMStar')\n",
    "  \n",
    "    # mppnp \n",
    "    ax.plot(r_mppnp[runstr],drhoHdt_mppnp_up[runstr],ls=ls[0],color=color[0],\n",
    "           label='Upstream',marker=marker[0],markevery=markevery[0])\n",
    "    cbc += 1\n",
    "    \n",
    "    ax.plot(r_mppnp[runstr],drhoHdt_mppnp_down[runstr],ls=ls[1],color=color[1],\n",
    "            label='Downstream',marker=marker[1],markevery=markevery[1])\n",
    "    cbc += 1\n",
    "    \n",
    "    ax.plot(r_mppnp[runstr],drhoHdt_mppnp_ud_avg[runstr],ls=ls[2],color=color[2],\n",
    "            label=r'$\\langle \\mathrm{Up},\\mathrm{Down} \\rangle$',marker=marker[2],markevery=markevery[2])\n",
    "    cbc += 1\n",
    "\n",
    "    ax.plot(r_mppnp[runstr],drhoHdt_mppnp_Dvr[runstr],ls=ls[3],color=color[3],\n",
    "            label=r'D$_{\\mathrm{vr}}$',marker=marker[3],markevery=markevery[3])\n",
    "    cbc += 1\n",
    "\n",
    "    ax.plot(r_mppnp[runstr],drhoHdt_mppnp_DFVvr[runstr],ls=ls[4],color=color[4],\n",
    "            label=r'D$_{\\mathrm{FV+vr}}$',marker=marker[4],markevery=markevery[4])\n",
    "    cbc += 1\n",
    "    \n",
    "    # plot details\n",
    "    ax.set_xlabel('r / Mm')\n",
    "    ax.set_ylabel(r'(d$\\rho_{\\mathrm{H}}$ / dt) / M$_{\\odot}$ s$^{-1}$ Mm$^{-3}$')\n",
    "    ax.legend(frameon=False)\n",
    "    rbot = m2r(myrun.mbot, myrun, myrun.dump0)\n",
    "    rtop = m2r(myrun.mtop, myrun, myrun.dump0)\n",
    "    ax.set_xlim([rbot, rtop])\n",
    "    ax.set_ylim([0, 2.25e-15])\n",
    " \n",
    "    # savefig\n",
    "    fig.tight_layout()\n",
    "    if save:\n",
    "        fig.savefig(savefig[runstr],bbox_inches = \"tight\",dpi=300)\n",
    "    if not render:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What temperature does the reaction begin to burn hydrogen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T9 = data['T9']\n",
    "r = data['r']\n",
    "T9_index = np.argmin(abs(r - 18))\n",
    "\n",
    "print('The temperature at R={:0.1f} is T9={:0.3f}'.format(r[T9_index], T9[T9_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HBurned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much H was burned throughout the simulation in each of the hydro models. Compare with the advective mixing model and with just the entrainment rate linear fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # taken from Hydro-Results.ipynb\n",
    "# n16_entr_slope = 7.21e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dictionary that are run dependent\n",
    "# Hburned_ud = collections.OrderedDict((run, []) for run in runs)\n",
    "# Hburned_ud_avg = collections.OrderedDict((run, []) for run in runs)\n",
    "# Hburned_Dvr = collections.OrderedDict((run, []) for run in runs)\n",
    "# Hburned_DFVvr = collections.OrderedDict((run, []) for run in runs)\n",
    "# Hburned_PPM = collections.OrderedDict((run, []) for run in runs)\n",
    "# dumpStart = collections.OrderedDict((run, []) for run in runs)\n",
    "# dumpEnd = collections.OrderedDict((run, []) for run in runs)\n",
    "\n",
    "# # loop through the different runs\n",
    "# for runstr, myrun in run.items():\n",
    "    \n",
    "#     # range of dumps to analyze\n",
    "#     dumpStart[runstr] = myrun.simDump0\n",
    "#     dumpEnd[runstr] = myrun.simDumpMax\n",
    "    \n",
    "#     # initialize zero arrays for Hburned\n",
    "#     Hburned_ud[runstr] = np.zeros(dumpEnd[runstr] - dumpStart[runstr])\n",
    "#     Hburned_ud_avg[runstr] = np.zeros(dumpEnd[runstr] - dumpStart[runstr])\n",
    "#     Hburned_Dvr[runstr] = np.zeros(dumpEnd[runstr] - dumpStart[runstr])\n",
    "#     Hburned_DFVvr[runstr] = np.zeros(dumpEnd[runstr] - dumpStart[runstr])\n",
    "#     Hburned_PPM[runstr] = np.zeros(dumpEnd[runstr] - dumpStart[runstr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # temperature corrections are needed...\n",
    "# T9corr_params = {'kind':1, 'params':{'a':0.46, 'b':0.77}}\n",
    "# burn_args = {'T9corr_params':T9corr_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loop through the different runs\n",
    "# for runstr, myrun in run.items():\n",
    "        \n",
    "#     # the dumps to loop over\n",
    "#     dumps = list(range(dumpStart[runstr],dumpEnd[runstr]))\n",
    "    \n",
    "#     for counter, dump in enumerate(dumps):\n",
    "        \n",
    "#         # get dt over the time step\n",
    "#         dt = np.diff(myrun.times)[dump]\n",
    "\n",
    "#         # get the dmXhdt from PPMStar\n",
    "#         r_PPM = myrun.rprof.get('R',fname=dump,resolution='l')                                         \n",
    "#         dV = -4 * np.pi * r_PPM**2 * ppm.cdiff(r_PPM)\n",
    "\n",
    "#         # try with the vc12pg equation I have\n",
    "#         Tcorr = myrun.rprof.compute_T9corr(fname=dump, kind=T9corr_params['kind'],\n",
    "#                                            params=T9corr_params['params'])\n",
    "#         rho = myrun.rprof.get('Rho0',fname=dump,resolution='l') + myrun.rprof.get('Rho1',fname=dump,resolution='l')\n",
    "#         Xcld = myrun.rprof.compute_Xcld(dump)\n",
    "#         XH = Xcld * fkcld * atomicnoH / atomicnocld\n",
    "#         XC12 = (1-Xcld) * fkair * atomicnoC12 / atomicnoair\n",
    "#         drhoHdt_PPM = drhoH_dt(XH, XC12, rho, Tcorr, -dV)\n",
    "\n",
    "#         # integrate space and time for PPMStar\n",
    "#         if counter == 0:\n",
    "#            Hburned_PPM[runstr][counter] = np.sum(drhoHdt_PPM * dV * dt)\n",
    "#         else:\n",
    "#            Hburned_PPM[runstr][counter] = np.sum(drhoHdt_PPM * dV * dt) + Hburned_PPM[runstr][counter-1]\n",
    "\n",
    "#         # For mppnp use shell files for rho, T and r. Use se for mass fractions  \n",
    "#         # I need to read in the structure for mppnp. It should be exactly the shell files\n",
    "#         data, header = readSCFile(myrun.initbase, 'shell', dump)\n",
    "#         rho_mppnp = shell2central(data['rho'])\n",
    "#         T9_mppnp = data['T9'][0:-1]\n",
    "#         r_mppnp = shell2central(data['r'])\n",
    "\n",
    "#         dV_mppnp = 2. * np.pi * r_mppnp**2 * ppm.cdiff(r_mppnp)\n",
    "\n",
    "#         XH_up = removelists(myrun.up_c12pg, 'H-1', dump2cycle(myrun.nrepeatDump0, myrun.nsubt, dump, myrun.simDump0))\n",
    "#         XH_down = removelists(myrun.down_c12pg, 'H-1', dump2cycle(myrun.nrepeatDump0, myrun.nsubt, dump, myrun.simDump0))\n",
    "#         XH_Dvr = removelists(myrun.Dvr_c12pg, 'H-1', dump2cycle(myrun.nrepeatDump0, myrun.nsubt, dump, myrun.simDump0))\n",
    "#         if runstr != 'n17':\n",
    "#             XH_DFVvr = removelists(myrun.DFVvr_c12pg, 'H-1', dump2cycle(myrun.nrepeatDump0, myrun.nsubt, dump, myrun.simDump0))\n",
    "\n",
    "#         XC12_up = removelists(myrun.up_c12pg, 'C-12', dump2cycle(myrun.nrepeatDump0, myrun.nsubt, dump, myrun.simDump0))\n",
    "#         XC12_down = removelists(myrun.down_c12pg, 'C-12', dump2cycle(myrun.nrepeatDump0, myrun.nsubt, dump, myrun.simDump0))\n",
    "#         XC12_Dvr = removelists(myrun.Dvr_c12pg, 'C-12', dump2cycle(myrun.nrepeatDump0, myrun.nsubt, dump, myrun.simDump0))\n",
    "#         if runstr != 'n17':\n",
    "#             XC12_DFVvr = removelists(myrun.DFVvr_c12pg, 'C-12', dump2cycle(myrun.nrepeatDump0, myrun.nsubt, dump, myrun.simDump0))\n",
    "\n",
    "#         drhoHdt_mppnp_up = drhoH_dt(XH_up, XC12_up, rho_mppnp, T9_mppnp, dV_mppnp)\n",
    "#         drhoHdt_mppnp_down = drhoH_dt(XH_down, XC12_down, rho_mppnp, T9_mppnp, dV_mppnp)\n",
    "#         drhoHdt_mppnp_ud_avg = drhoH_dt((XH_down+XH_up)/2., (XC12_down +XC12_up)/2., rho_mppnp, T9_mppnp, 2*dV_mppnp)\n",
    "#         drhoHdt_mppnp_Dvr = drhoH_dt(XH_Dvr, XC12_Dvr, rho_mppnp, T9_mppnp, 2*dV_mppnp)\n",
    "#         if runstr != 'n17':\n",
    "#             drhoHdt_mppnp_DFVvr = drhoH_dt(XH_DFVvr, XC12_DFVvr, rho_mppnp, T9_mppnp, 2*dV_mppnp)\n",
    "#         else:\n",
    "#             drhoHdt_mppnp_DFVvr = 0.\n",
    "\n",
    "#         # integrate space and time for simulation (mppnp)\n",
    "#         if counter == 0:\n",
    "#            Hburned_ud[runstr][counter] = np.sum((drhoHdt_mppnp_up + drhoHdt_mppnp_down) * dV_mppnp * dt)\n",
    "#            Hburned_ud_avg[runstr][counter] = np.sum((drhoHdt_mppnp_ud_avg) * 2 * dV_mppnp * dt)\n",
    "#            Hburned_Dvr[runstr][counter] = np.sum(drhoHdt_mppnp_Dvr * 2 * dV_mppnp * dt)\n",
    "#            Hburned_DFVvr[runstr][counter] = np.sum(drhoHdt_mppnp_DFVvr * 2 * dV_mppnp * dt)\n",
    "#         else:\n",
    "#            Hburned_ud[runstr][counter] = np.sum((drhoHdt_mppnp_up + drhoHdt_mppnp_down) * dV_mppnp * dt) + Hburned_ud[runstr][counter-1]\n",
    "#            Hburned_ud_avg[runstr][counter] = np.sum((drhoHdt_mppnp_ud_avg) * 2 * dV_mppnp * dt) + Hburned_ud_avg[runstr][counter-1]\n",
    "#            Hburned_Dvr[runstr][counter] = np.sum(drhoHdt_mppnp_Dvr * 2 * dV_mppnp * dt) + Hburned_Dvr[runstr][counter-1]\n",
    "#            Hburned_DFVvr[runstr][counter] = np.sum(drhoHdt_mppnp_DFVvr * 2 * dV_mppnp * dt) + Hburned_DFVvr[runstr][counter-1]\n",
    "\n",
    "#     # make burning equal to zero at the start\n",
    "#     Hburned_PPM[runstr] -= Hburned_PPM[runstr][0]\n",
    "#     Hburned_ud[runstr] -= Hburned_ud[runstr][0]\n",
    "#     Hburned_ud_avg[runstr] -= Hburned_ud_avg[runstr][0]    \n",
    "#     Hburned_Dvr[runstr] -= Hburned_Dvr[runstr][0]\n",
    "#     Hburned_DFVvr[runstr] -= Hburned_DFVvr[runstr][0]\n",
    "    \n",
    "#     # make Hburned in solar mass\n",
    "#     Hburned_PPM[runstr] *= 1e27/ast.msun_g\n",
    "#     Hburned_ud[runstr] *= 1e27/ast.msun_g\n",
    "#     Hburned_ud_avg[runstr] *= 1e27/ast.msun_g\n",
    "#     Hburned_Dvr[runstr] *= 1e27/ast.msun_g\n",
    "#     Hburned_DFVvr[runstr] *= 1e27/ast.msun_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot dependent dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if i want to look at one particular run and/or radii\n",
    "# runs_plot = ['n16', 'n17']\n",
    "\n",
    "# # plot stuff\n",
    "# savefig = 'Hburned.pdf'\n",
    "# render = True\n",
    "# save = False\n",
    "# thickline = collections.OrderedDict(zip(run.keys(), [1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# celln = 19\n",
    "\n",
    "# # configure plots\n",
    "# close_local = ppm.close_plot(celln,ifig,ptrack)\n",
    "# if close_local[0]:\n",
    "#     plt.close(fig); ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "#     ppm.add_plot(celln,ifig,ptrack)\n",
    "# else:\n",
    "#     ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "#     ppm.add_plot(celln,ifig,ptrack)\n",
    "\n",
    "# ax = fig.add_subplot(111)\n",
    "\n",
    "# # loop through every run\n",
    "# for runstr, myrun in run.items():\n",
    "    \n",
    "#     # are we working with every run?\n",
    "#     if runstr not in runs_plot:\n",
    "#         continue\n",
    "    \n",
    "#     cbc = 0\n",
    "    \n",
    "#     # plot the total burned\n",
    "#     if runstr != 'n16':\n",
    "        \n",
    "#         # PPM\n",
    "#         ax.plot((myrun.times - myrun.times[myrun.simDump0])[myrun.simDump0:myrun.simDumpMax] / 60.,\n",
    "#                 Hburned_PPM[runstr],ls=cb(cbc)[0],color=cb(cbc)[2],linewidth=thickline[runstr])\n",
    "#         cbc += 1\n",
    "        \n",
    "#         # ud\n",
    "#         ax.plot((myrun.times - myrun.times[myrun.simDump0])[myrun.simDump0:myrun.simDumpMax] / 60.,\n",
    "#                 Hburned_ud[runstr],ls=cb(cbc)[0],color=cb(cbc)[2],linewidth=thickline[runstr])\n",
    "#         cbc += 1\n",
    "        \n",
    "#         # Jones\n",
    "#         ax.plot((myrun.times - myrun.times[myrun.simDump0])[myrun.simDump0:myrun.simDumpMax] / 60.,\n",
    "#                 Hburned_Dvr[runstr],ls=cb(cbc)[0],color=cb(cbc)[2],linewidth=thickline[runstr])\n",
    "#         cbc += 1  \n",
    "        \n",
    "#         # DFV+vr\n",
    "#         ax.plot((myrun.times - myrun.times[myrun.simDump0])[myrun.simDump0:myrun.simDumpMax] / 60.,\n",
    "#                 Hburned_DFVvr[runstr],ls=cb(cbc)[0],color=cb(cbc)[2],linewidth=thickline[runstr])\n",
    "#         cbc += 1    \n",
    "        \n",
    "#     else:\n",
    "#         # PPM\n",
    "#         ax.plot((myrun.times - myrun.times[myrun.simDump0])[myrun.simDump0:myrun.simDumpMax] / 60.,\n",
    "#                 Hburned_PPM[runstr],ls=cb(cbc)[0],color=cb(cbc)[2],label='PPMStar',linewidth=thickline[runstr])\n",
    "#         cbc += 1\n",
    "        \n",
    "#         # ud\n",
    "#         ax.plot((myrun.times - myrun.times[myrun.simDump0])[myrun.simDump0:myrun.simDumpMax] / 60.,\n",
    "#                 Hburned_ud[runstr],ls=cb(cbc)[0],color=cb(cbc)[2],label='Advection',linewidth=thickline[runstr])\n",
    "#         cbc += 1\n",
    "\n",
    "#         # Jones\n",
    "#         ax.plot((myrun.times - myrun.times[myrun.simDump0])[myrun.simDump0:myrun.simDumpMax] / 60.,\n",
    "#                 Hburned_Dvr[runstr],ls=cb(cbc)[0],color=cb(cbc)[2],label=r'D$_{\\mathrm{vr}}$',linewidth=thickline[runstr])\n",
    "#         cbc += 1  \n",
    "        \n",
    "#         # DFV+vr\n",
    "#         ax.plot((myrun.times - myrun.times[myrun.simDump0])[myrun.simDump0:myrun.simDumpMax] / 60.,\n",
    "#                 Hburned_DFVvr[runstr],ls=cb(cbc)[0],color=cb(cbc)[2],label=r'D$_{\\mathrm{FV+vr}}$',linewidth=thickline[runstr])\n",
    "#         cbc += 1     \n",
    "        \n",
    "# # plot details\n",
    "# ax.set_xlabel('t / min')\n",
    "# ax.set_ylabel(r'Mass of H Burned / M$_{\\odot}$')\n",
    "# xlims = ax.get_xlim()\n",
    "# ylims = ax.get_ylim()\n",
    "# ax.set_xlim([0,xlims[-1]])\n",
    "# ax.set_ylim([1e-8,ylims[-1]])\n",
    "# ax.set_yscale('log')\n",
    "# # ax.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "# ax.legend(frameon=False)\n",
    "\n",
    "# # savefig\n",
    "# fig.tight_layout()\n",
    "# fig.savefig(savefig,bbox_inches = \"tight\",dpi=300)\n",
    "# if not render:\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C12pg Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this uses the previous sections variable \"run_dump\". These profiles MUST be the same as the rates for a useful comparison in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary that are run dependent\n",
    "XHrprof = collections.OrderedDict((run, []) for run in runs)\n",
    "XHmppnpU = collections.OrderedDict((run, []) for run in runs)\n",
    "XHmppnpD = collections.OrderedDict((run, []) for run in runs)\n",
    "XHmppnpAvg = collections.OrderedDict((run, []) for run in runs)\n",
    "XHmppnpDvr = collections.OrderedDict((run, []) for run in runs)\n",
    "XHmppnpDFVvr = collections.OrderedDict((run, []) for run in runs)\n",
    "rrprof = collections.OrderedDict((run, []) for run in runs)\n",
    "rmppnp = collections.OrderedDict((run, []) for run in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the different runs\n",
    "for runstr, myrun in run.items():\n",
    "\n",
    "    # get the rprof \"rprof\"\n",
    "    rrprof[runstr] = myrun.rprof.get('R',fname=run_dump[runstr],resolution='l')\n",
    "    X_rprof = myrun.rprof.compute_Xcld(fname=run_dump[runstr])\n",
    "    XHrprof[runstr] = X_rprof * fkcld * (atomicnoH / atomicnocld)\n",
    "    \n",
    "    # mppnp, use shell files for radii\n",
    "    data, header = readSCFile(myrun.initbase, 'shell', run_dump[runstr])\n",
    "    rmppnp[runstr] = shell2central(data['r'])\n",
    "\n",
    "    XHmppnpU[runstr] = removelists(myrun.up_c12pg, 'H-1', \n",
    "                                   dump2cycle(myrun.nrepeatDump0, myrun.nsubt, run_dump[runstr], myrun.simDump0))\n",
    "    XHmppnpD[runstr] = removelists(myrun.down_c12pg, 'H-1', \n",
    "                                   dump2cycle(myrun.nrepeatDump0, myrun.nsubt, run_dump[runstr], myrun.simDump0))\n",
    "    XHmppnpAvg[runstr] = (XHmppnpU[runstr] + XHmppnpD[runstr]) / 2.\n",
    "    XHmppnpDvr[runstr] = removelists(myrun.Dvr_c12pg, 'H-1', \n",
    "                                     dump2cycle(myrun.nrepeatDump0, myrun.nsubt, run_dump[runstr], myrun.simDump0))\n",
    "    if runstr != 'n17':\n",
    "        XHmppnpDFVvr[runstr] = removelists(myrun.DFVvr_c12pg, 'H-1', \n",
    "                                           dump2cycle(myrun.nrepeatDump0, myrun.nsubt, run_dump[runstr], myrun.simDump0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advection C12pg Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if i want to look at one particular run and/or radii\n",
    "runs_plot = ['n16', 'n17']\n",
    "\n",
    "# plot stuff\n",
    "savefig = collections.OrderedDict((run, []) for run in runs)\n",
    "\n",
    "for runstr, myrun in run.items():\n",
    "    savefig[runstr] = '{:s}-adv-c12pg-XHrprofs.pdf'.format(runstr.capitalize())\n",
    "    \n",
    "render = True\n",
    "save = True\n",
    "\n",
    "# run dependent quantities\n",
    "XHmin = collections.OrderedDict(zip(run.keys(), [1e-8, 1e-8]))\n",
    "XHmax = collections.OrderedDict(zip(run.keys(), [1e-3, 1e-2]))\n",
    "entr_offset = collections.OrderedDict(zip(run.keys(), [0.5, 5.0]))\n",
    "\n",
    "# for any run, plot quantity dependencies\n",
    "ls = ['-', '--', '-.']\n",
    "color = [cb(1)[2], cb(2)[2], cb(3)[2]]\n",
    "marker = ['>', '<', None]\n",
    "markevery = [30, 30, 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 23\n",
    "\n",
    "# loop through every run\n",
    "for runstr, myrun in run.items():\n",
    "    \n",
    "    # are we working with every run?\n",
    "    if runstr not in runs_plot:\n",
    "        continue\n",
    "\n",
    "    # celln\n",
    "    celln += 1\n",
    "\n",
    "    # configure plots\n",
    "    close_local = ppm.close_plot(celln,ifig,ptrack)\n",
    "    if close_local[0]:\n",
    "        plt.close(fig); ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "        ppm.add_plot(celln,ifig,ptrack)\n",
    "    else:\n",
    "        ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "        ppm.add_plot(celln,ifig,ptrack)\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "    cbc = 0\n",
    "\n",
    "    # rprof boundaries\n",
    "    XHrange = [XHmin[runstr],XHmax[runstr]]\n",
    "    rRange = [rmppnp[runstr].min() - 12*np.abs(np.diff(rmppnp[runstr]).mean()),\n",
    "              rmppnp[runstr].max() + 12*np.abs(np.diff(rmppnp[runstr]).mean())]\n",
    "\n",
    "    # add a vertical line for the entrainment rate measurement\n",
    "    xline = m2r(myrun.mtop, myrun, run_dump[runstr]) - entr_offset[runstr]\n",
    "    ax.vlines(xline, *XHrange, color='k', linestyle=':',linewidth=0.8)\n",
    "\n",
    "    # PPMstar\n",
    "    ax.plot(rrprof[runstr], XHrprof[runstr], label='PPMStar', ls=cb(0)[0], color=cb(0)[2])\n",
    "\n",
    "    # mppnp\n",
    "    ax.plot(rmppnp[runstr], XHmppnpU[runstr], label='Upstream', ls=ls[0], color=color[0], \n",
    "           marker=marker[0], markevery=markevery[0])\n",
    "\n",
    "    ax.plot(rmppnp[runstr], XHmppnpD[runstr], label='Downstream', ls=ls[1], color=color[1], \n",
    "           marker=marker[1], markevery=markevery[1])    \n",
    "\n",
    "    ax.plot(rmppnp[runstr],XHmppnpAvg[runstr], label=r'$\\langle \\mathrm{Up},\\mathrm{Down} \\rangle$', \n",
    "            ls=ls[2], color=color[2], marker=marker[2], markevery=markevery[2])    \n",
    "\n",
    "    # ax2 properties\n",
    "    ax.set_xlabel('r / Mm')\n",
    "    ax.set_ylabel('X$_{\\mathrm{H}}$')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(XHrange)\n",
    "    ax.set_xlim(rRange)\n",
    "    ax.legend(frameon=False, loc='upper left')\n",
    "\n",
    "    # savefig\n",
    "    fig.tight_layout()\n",
    "    if save:\n",
    "        fig.savefig(savefig[runstr],bbox_inches = \"tight\",dpi=300)\n",
    "    if not render:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diffusion C12pg Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if i want to look at one particular run and/or radii\n",
    "runs_plot = ['n16']\n",
    "\n",
    "# plot stuff\n",
    "savefig = collections.OrderedDict((run, []) for run in runs)\n",
    "\n",
    "for runstr, myrun in run.items():\n",
    "    savefig[runstr] = '{:s}-diff-c12pg-XHrprofs.pdf'.format(runstr.capitalize())\n",
    "    \n",
    "render = True\n",
    "save = True\n",
    "\n",
    "# run dependent quantities\n",
    "XHmin = collections.OrderedDict(zip(run.keys(), [1e-8, 1e-8]))\n",
    "XHmax = collections.OrderedDict(zip(run.keys(), [1e-3, 1e-2]))\n",
    "entr_offset = collections.OrderedDict(zip(run.keys(), [0.5, 5.0]))\n",
    "\n",
    "# for any run, plot quantity dependencies\n",
    "ls = ['-.', ':']\n",
    "color = [cb(1)[2], cb(2)[2]]\n",
    "marker = ['o', 'x']\n",
    "markevery = [30, 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 25\n",
    "\n",
    "# loop through every run\n",
    "for runstr, myrun in run.items():\n",
    "    \n",
    "    # are we working with every run?\n",
    "    if runstr not in runs_plot:\n",
    "        continue\n",
    "\n",
    "    # celln\n",
    "    celln += 1\n",
    "\n",
    "    # configure plots\n",
    "    close_local = ppm.close_plot(celln,ifig,ptrack)\n",
    "    if close_local[0]:\n",
    "        plt.close(fig); ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "        ppm.add_plot(celln,ifig,ptrack)\n",
    "    else:\n",
    "        ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "        ppm.add_plot(celln,ifig,ptrack)\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "    cbc = 0\n",
    "\n",
    "    # rprof boundaries\n",
    "    XHrange = [XHmin[runstr],XHmax[runstr]]\n",
    "    rRange = [rmppnp[runstr].min() - 12*np.abs(np.diff(rmppnp[runstr]).mean()),\n",
    "              rmppnp[runstr].max() + 12*np.abs(np.diff(rmppnp[runstr]).mean())]\n",
    "\n",
    "    # add a vertical line for the entrainment rate measurement\n",
    "    xline = m2r(myrun.mtop, myrun, run_dump[runstr]) - entr_offset[runstr]\n",
    "    ax.vlines(xline, *XHrange, color='k', linestyle=':',linewidth=0.8)\n",
    "\n",
    "    # PPMstar\n",
    "    ax.plot(rrprof[runstr], XHrprof[runstr], label='PPMStar', ls=cb(0)[0], color=cb(0)[2])\n",
    "\n",
    "    # mppnp\n",
    "    ax.plot(rmppnp[runstr], XHmppnpDvr[runstr], label=r'D$_{\\mathrm{vr}}$', ls=ls[0], color=color[0], \n",
    "           marker=marker[0], markevery=markevery[0])\n",
    "\n",
    "    ax.plot(rmppnp[runstr], XHmppnpDFVvr[runstr], label=r'D$_{\\mathrm{FV+vr}}$', ls=ls[1], color=color[1], \n",
    "           marker=marker[1], markevery=markevery[1])    \n",
    "\n",
    "    # ax2 properties\n",
    "    ax.set_xlabel('r / Mm')\n",
    "    ax.set_ylabel('X$_{\\mathrm{H}}$')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(XHrange)\n",
    "    ax.set_xlim(rRange)\n",
    "    ax.legend(frameon=False, loc='upper left')\n",
    "\n",
    "    # savefig\n",
    "    fig.tight_layout()\n",
    "    if save:\n",
    "        fig.savefig(savefig[runstr],bbox_inches = \"tight\",dpi=300)\n",
    "    if not render:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for different plots at different times\n",
    "run_calc = ['n16', 'n17']\n",
    "\n",
    "# in case we want PPMStar\n",
    "XHrprof = collections.OrderedDict((run, []) for run in runs)\n",
    "\n",
    "# for different species\n",
    "species = ['H-1', 'N-13', 'C-13', 'Kr-88', 'Kr-89', 'Kr-90']\n",
    "\n",
    "# dictionary that are run and time dependent\n",
    "XmppnpU = collections.OrderedDict((run, \n",
    "                                collections.OrderedDict(zip(species, \n",
    "                                                            [1]*len(species)))) for run in runs)\n",
    "XmppnpD = collections.OrderedDict((run, \n",
    "                                collections.OrderedDict(zip(species, \n",
    "                                                            [1]*len(species)))) for run in runs)\n",
    "XmppnpDFVvr = collections.OrderedDict((run, \n",
    "                                collections.OrderedDict(zip(species, \n",
    "                                                            [1]*len(species)))) for run in runs)\n",
    "XmppnpDvr = collections.OrderedDict((run, \n",
    "                                collections.OrderedDict(zip(species, \n",
    "                                                            [1]*len(species)))) for run in runs)\n",
    "\n",
    "rrprof = collections.OrderedDict((run, []) for run in runs)\n",
    "rmppnp = collections.OrderedDict((run, []) for run in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the different runs\n",
    "for runstr, myrun in run.items():\n",
    "\n",
    "    # do we even have the data?\n",
    "    if runstr not in run_calc:\n",
    "        continue\n",
    "    \n",
    "    # get the rprof \"rprof\"\n",
    "    rrprof[runstr] = myrun.rprof.get('R',fname=run_dump[runstr],resolution='l')\n",
    "    X_rprof = myrun.rprof.compute_Xcld(fname=run_dump[runstr])\n",
    "    XHrprof[runstr] = X_rprof * fkcld * (atomicnoH / atomicnocld)\n",
    "    \n",
    "    # mppnp, use shell files for radii\n",
    "    data, header = readSCFile(myrun.initbase, 'shell', run_dump[runstr])\n",
    "    rmppnp[runstr] = shell2central(data['r'])\n",
    "\n",
    "    \n",
    "    # now for every species\n",
    "    for specie in species:\n",
    "\n",
    "        XmppnpU[runstr][specie] = removelists(myrun.up_fnet, specie, \n",
    "                                       dump2cycle(myrun.nrepeatDump0, myrun.nsubt, run_dump[runstr], myrun.simDump0))\n",
    "        XmppnpD[runstr][specie] = removelists(myrun.down_fnet, specie, \n",
    "                                       dump2cycle(myrun.nrepeatDump0, myrun.nsubt, run_dump[runstr], myrun.simDump0))\n",
    "        XmppnpDvr[runstr][specie] = removelists(myrun.Dvr_fnet, specie, \n",
    "                                         dump2cycle(myrun.nrepeatDump0, myrun.nsubt, run_dump[runstr], myrun.simDump0))\n",
    "        if runstr != 'n17':\n",
    "            XmppnpDFVvr[runstr][specie] = removelists(myrun.DFVvr_fnet, specie, \n",
    "                                               dump2cycle(myrun.nrepeatDump0, myrun.nsubt, run_dump[runstr], myrun.simDump0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advection and Diffusion H,N13,C13 Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if i want to look at one particular run and/or radii\n",
    "runs_plot = ['n16', 'n17']\n",
    "\n",
    "# plot stuff\n",
    "savefig = collections.OrderedDict((run, []) for run in runs)\n",
    "\n",
    "for runstr, myrun in run.items():\n",
    "    savefig[runstr] = '{:s}-HN13C13-fnet.pdf'.format(runstr.capitalize())\n",
    "    \n",
    "render = True\n",
    "save = True\n",
    "\n",
    "# run dependent quantities\n",
    "Xmin = collections.OrderedDict(zip(run.keys(), [2e-11, 1e-8]))\n",
    "Xmax = collections.OrderedDict(zip(run.keys(), [2e-4, 1e-2]))\n",
    "\n",
    "# for any run, plot quantity dependencies\n",
    "plot_species = ['H-1', 'N-13', 'C-13']\n",
    "species_latex = [r'H', r'$\\mathrm{^{13}N}$', r'$\\mathrm{^{13}C}$']\n",
    "species_labels = collections.OrderedDict(zip(plot_species, species_latex))\n",
    "ls = ['-', '--', '-.', ':']\n",
    "color = [cb(1)[2], cb(2)[2], cb(5)[2]]\n",
    "marker = ['>', '<', 'o', 'x']\n",
    "markevery = [30]*len(marker)\n",
    "markersize = [4]*len(markevery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 29\n",
    "\n",
    "# loop through every run\n",
    "for runstr, myrun in run.items():\n",
    "    \n",
    "    # are we working with every run?\n",
    "    if runstr not in runs_plot:\n",
    "        continue\n",
    "\n",
    "    # celln\n",
    "    celln += 1\n",
    "\n",
    "    # configure plots\n",
    "    close_local = ppm.close_plot(celln,ifig,ptrack)\n",
    "    if close_local[0]:\n",
    "        plt.close(fig); ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "        ppm.add_plot(celln,ifig,ptrack)\n",
    "    else:\n",
    "        ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "        ppm.add_plot(celln,ifig,ptrack)\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "    cbc = 0\n",
    "\n",
    "    # rprof boundaries\n",
    "    Xrange = [Xmin[runstr],Xmax[runstr]]\n",
    "    rRange = [rmppnp[runstr].min() - 12*np.abs(np.diff(rmppnp[runstr]).mean()),\n",
    "              rmppnp[runstr].max() + 12*np.abs(np.diff(rmppnp[runstr]).mean())]\n",
    "\n",
    "    # mppnp, for the species in the plot_species\n",
    "    for i,specie in enumerate(plot_species):\n",
    "        \n",
    "        if specie == 'H-1':\n",
    "            ax.plot(rrprof[runstr], XHrprof[runstr], label='PPMStar H', ls=cb(0)[0], color=cb(0)[2])\n",
    "            \n",
    "        ax.plot(rmppnp[runstr], XmppnpU[runstr][specie], label=species_labels[specie], ls=ls[0], \n",
    "                color=color[i], marker=marker[0], markevery=markevery[0], markersize=markersize[0])\n",
    "        ax.plot(rmppnp[runstr], XmppnpD[runstr][specie], ls=ls[1], color=color[i], \n",
    "               marker=marker[1], markevery=markevery[1], markersize=markersize[1])\n",
    "        ax.plot(rmppnp[runstr], XmppnpDvr[runstr][specie], ls=ls[2], color=color[i], \n",
    "               marker=marker[2], markevery=markevery[2], markersize=markersize[2])\n",
    "        if runstr != 'n17':\n",
    "            ax.plot(rmppnp[runstr], XmppnpDFVvr[runstr][specie], ls=ls[3], color=color[i], \n",
    "                   marker=marker[3], markevery=markevery[3], markersize=markersize[3])\n",
    "\n",
    "    # ax2 properties\n",
    "    ax.set_xlabel('r / Mm')\n",
    "    ax.set_ylabel('X')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(Xrange)\n",
    "    ax.set_xlim(rRange)\n",
    "    ax.legend(frameon=False, loc='lower right')\n",
    "\n",
    "    # savefig\n",
    "    fig.tight_layout()\n",
    "    if save:\n",
    "        fig.savefig(savefig[runstr],bbox_inches = \"tight\",dpi=300)\n",
    "    if not render:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advection and Diffusion Kr Isotopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if i want to look at one particular run and/or radii\n",
    "runs_plot = ['n16', 'n17']\n",
    "\n",
    "# plot stuff\n",
    "savefig = collections.OrderedDict((run, []) for run in runs)\n",
    "\n",
    "for runstr, myrun in run.items():\n",
    "    savefig[runstr] = '{:s}-Kr-isotopes-fnet.pdf'.format(runstr.capitalize())\n",
    "    \n",
    "render = True\n",
    "save = True\n",
    "\n",
    "# run dependent quantities\n",
    "Xmin = collections.OrderedDict(zip(run.keys(), [1e-20, 1e-16]))\n",
    "Xmax = collections.OrderedDict(zip(run.keys(), [1e-10, 1e-9]))\n",
    "\n",
    "# for any run, plot quantity dependencies\n",
    "plot_species = ['Kr-88', 'Kr-89','Kr-90']\n",
    "species_latex = [r'$\\mathrm{^{88}Kr}$', r'$\\mathrm{^{89}Kr}$', r'$\\mathrm{^{90}Kr}$']\n",
    "species_labels = collections.OrderedDict(zip(plot_species, species_latex))\n",
    "ls = ['-', '--', '-.', ':']\n",
    "color = [cb(4)[2], cb(6)[2], cb(8)[2], cb(6)[2], cb(7)[2]]\n",
    "marker = ['>', '<', 'o', 'x']\n",
    "markevery = [30]*len(marker)\n",
    "markersize = [4]*len(markevery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 34\n",
    "\n",
    "# loop through every run\n",
    "for runstr, myrun in run.items():\n",
    "    \n",
    "    # are we working with every run?\n",
    "    if runstr not in runs_plot:\n",
    "        continue\n",
    "\n",
    "    # celln\n",
    "    celln += 1\n",
    "\n",
    "    # configure plots\n",
    "    close_local = ppm.close_plot(celln,ifig,ptrack)\n",
    "    if close_local[0]:\n",
    "        plt.close(fig); ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "        ppm.add_plot(celln,ifig,ptrack)\n",
    "    else:\n",
    "        ifig += 1; fig = plt.figure(ifig,figsize=(stdRatio*stdSize,stdSize),dpi=300)\n",
    "        ppm.add_plot(celln,ifig,ptrack)\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "    cbc = 0\n",
    "\n",
    "    # rprof boundaries\n",
    "    Xrange = [Xmin[runstr],Xmax[runstr]]\n",
    "    rRange = [rmppnp[runstr].min() - 12*np.abs(np.diff(rmppnp[runstr]).mean()),\n",
    "              rmppnp[runstr].max() + 12*np.abs(np.diff(rmppnp[runstr]).mean())]\n",
    "\n",
    "    # mppnp, for the species in the plot_species\n",
    "    for i,specie in enumerate(plot_species):\n",
    "\n",
    "        ax.plot(rmppnp[runstr], XmppnpU[runstr][specie], label=species_labels[specie], ls=ls[0], \n",
    "                color=color[i], marker=marker[0], markevery=markevery[0], markersize=markersize[0])\n",
    "        ax.plot(rmppnp[runstr], XmppnpD[runstr][specie], ls=ls[1], color=color[i], \n",
    "               marker=marker[1], markevery=markevery[1], markersize=markersize[1])\n",
    "        ax.plot(rmppnp[runstr], XmppnpDvr[runstr][specie], ls=ls[2], color=color[i], \n",
    "               marker=marker[2], markevery=markevery[2], markersize=markersize[2])\n",
    "        if runstr != 'n17':\n",
    "            ax.plot(rmppnp[runstr], XmppnpDFVvr[runstr][specie], ls=ls[3], color=color[i], \n",
    "                   marker=marker[3], markevery=markevery[3], markersize=markersize[3])\n",
    "\n",
    "    # ax2 properties\n",
    "    ax.set_xlabel('r / Mm')\n",
    "    ax.set_ylabel('X')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(Xrange)\n",
    "    ax.set_xlim(rRange)\n",
    "    ax.legend(frameon=False, loc='best')\n",
    "\n",
    "    # savefig\n",
    "    fig.tight_layout()\n",
    "    if save:\n",
    "        fig.savefig(savefig[runstr],bbox_inches = \"tight\",dpi=300)\n",
    "    if not render:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
